{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import _pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from alexnet_backprop import *\n",
    "from alexnet_guided_bp_vanilla import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load test set images\n",
    "test_images = open('test_set_17_227.pkl', \"rb\")\n",
    "data_set = _pickle.load(test_images) \n",
    "actor_code = get_actor_code(data_set)[0]\n",
    "reversed_actor_code = get_actor_code(data_set)[1]\n",
    "\n",
    "# load weights\n",
    "alexnet_weight_file = 'alexnet_weights.pkl'\n",
    "\n",
    "weight_fpath = 'tl17_result_trial2/'\n",
    "weight_fname = 'transfer_learning_fc_weights_17_trial2.pkl' \n",
    "tl_weight_file = weight_fpath + weight_fname\n",
    "\n",
    "weight_fpath = 'e2e17_result_trial2/'\n",
    "weight_fname = 'end_to_end_learning_weights_17_trial2.pkl' \n",
    "e2e_weight_file = weight_fpath + weight_fname\n",
    "\n",
    "weight_fpath = 'e2e17_result_trial2_ld/'\n",
    "weight_fname = 'end_to_end_learning_weights_17_trial2_ld.pkl' \n",
    "lessdecay_e2e_weight_file = weight_fpath + weight_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_true_class_saliency(data_set, graph, sess, fname):\n",
    "    \n",
    "    # save saliencies in an external array\n",
    "    saliency_masks = {}\n",
    "    for actor in data_set:\n",
    "        saliency_masks[actor] = np.zeros((0,227,227))\n",
    "    saliency_masked = {}\n",
    "    for actor in data_set:\n",
    "        saliency_masked[actor] = np.zeros((0,227,227,3))\n",
    "    \n",
    "    \n",
    "    plt.figure(dpi=70, figsize=(140, 100))\n",
    "    col=0\n",
    "    for actor in data_set:\n",
    "        row = 0 \n",
    "        for _ in range(len(data_set[actor])):\n",
    "            \n",
    "            # forward pass\n",
    "            image = data_set[actor][_].astype(np.float64)\n",
    "            image_feed = np.expand_dims(image,0)\n",
    "            probabilities = sess.run(graph.probabilities, feed_dict={graph.inputs:image_feed})[0]\n",
    "    \n",
    "            # plot original image\n",
    "            index = row*len(data_set)*2 + col +1\n",
    "            plt.subplots_adjust(bottom = 0., wspace=0.15, hspace = 0.1, top=0.5)\n",
    "            plt.subplot(len(data_set[actor]), len(data_set)*2, index)\n",
    "            plt.axis('off')\n",
    "            plt.title(\"True: \" + actor + \"\\n Pred: \" + actor_code[np.argmax(probabilities)], fontsize=10)\n",
    "            plt.imshow(image.astype('uint8'))\n",
    "    \n",
    "            # plot true class_saliency\n",
    "            i = reversed_actor_code[actor]\n",
    "            one_hot = np.zeros(len(actor_code))\n",
    "            one_hot[i] = 1\n",
    "            plt.subplot(len(data_set[actor]), len(data_set)*2, index+1)\n",
    "            plt.axis('off')\n",
    "            plt.title(actor + '\\n' + str(probabilities[i]), fontsize=14)\n",
    "            detailed_saliency = guided_backprop(graph, image, one_hot, sess)\n",
    "            saliency = np.sum(detailed_saliency, axis=-1)\n",
    "            saliency_rank = saliency.ravel().argsort().argsort().reshape(saliency.shape)\n",
    "            saliency_mask = (saliency_rank > 227*227*0.95).astype(float)\n",
    "            masked_saliency = np.expand_dims(saliency_mask, axis=-1)*detailed_saliency\n",
    "            \n",
    "            plt.imshow(masked_saliency)\n",
    "\n",
    "            saliency_masked[actor] = np.vstack((saliency_masked[actor], np.expand_dims(masked_saliency, axis=0)))\n",
    "            saliency_masks[actor] = np.vstack((saliency_masks[actor], np.expand_dims(saliency_mask, axis=0)))\n",
    "            row += 1\n",
    "        col += 2\n",
    "    plt.savefig(fname +'.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    pickle_out = open(fname +\".pkl\",\"wb\")\n",
    "    _pickle.dump(saliency_masked, pickle_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters and backprop variants\n",
    "tau = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "b_graph = backprop_graph(17, 100, alexnet_face_classifier)\n",
    "b_graph.classifier_graph(temp=tau)\n",
    "b_graph.guided_backprop_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('weight comparison')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1W (11, 11, 3, 96)\n",
      "1 conv1b (96,)\n",
      "2 conv2W (5, 5, 48, 256)\n",
      "3 conv2b (256,)\n",
      "4 conv3W (3, 3, 256, 384)\n",
      "5 conv3b (384,)\n",
      "6 conv4W (3, 3, 192, 384)\n",
      "7 conv4b (384,)\n",
      "8 conv5W (3, 3, 192, 256)\n",
      "9 conv5b (256,)\n",
      "0 fc1W (43264, 100)\n",
      "1 fc1b (100,)\n",
      "2 fc2W (100, 17)\n",
      "3 fc2b (17,)\n"
     ]
    }
   ],
   "source": [
    "# first generate the saliency using original alexnet + tl weights\n",
    "with tf.Session() as sess:\n",
    "    b_graph.cnn.load_weights(alexnet_weight_file, sess, conv_only = True)\n",
    "    b_graph.cnn.load_weights(tl_weight_file, sess, fc_only = True)\n",
    "    generate_true_class_saliency(data_set, b_graph, sess, 'weight comparison/tl_saliency_robust_detail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1W (11, 11, 3, 96)\n",
      "1 conv1b (96,)\n",
      "2 conv2W (5, 5, 48, 256)\n",
      "3 conv2b (256,)\n",
      "4 conv3W (3, 3, 256, 384)\n",
      "5 conv3b (384,)\n",
      "6 conv4W (3, 3, 192, 384)\n",
      "7 conv4b (384,)\n",
      "8 conv5W (3, 3, 192, 256)\n",
      "9 conv5b (256,)\n",
      "10 fc1W (43264, 100)\n",
      "11 fc1b (100,)\n",
      "12 fc2W (100, 17)\n",
      "13 fc2b (17,)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    b_graph.cnn.load_weights(e2e_weight_file, sess)\n",
    "    generate_true_class_saliency(data_set, b_graph, sess, 'weight comparison/e2e_saliency_robust_detail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(alexnet_weight_file, 'rb') as handle:\n",
    "    alexnet_weights = _pickle.load(handle)\n",
    "\n",
    "with open(e2e_weight_file, 'rb') as handle:\n",
    "    e2e_weights = _pickle.load(handle)\n",
    "\n",
    "# with open(lessdecay_e2e_weight_file, 'rb') as handle:\n",
    "#     lessdecay_e2e_weights = _pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conv1W', 'conv1b', 'conv2W', 'conv2b', 'conv3W', 'conv3b', 'conv4W', 'conv4b', 'conv5W', 'conv5b', 'fc1W', 'fc1b', 'fc2W', 'fc2b', 'fc3W', 'fc3b'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1W\n",
      "0.132202708907\n",
      "conv2W\n",
      "0.252965494792\n",
      "conv3W\n",
      "0.287393075448\n",
      "conv4W\n",
      "0.240549346547\n",
      "conv5W\n",
      "0.224932635272\n",
      "conv1W\n",
      "0.159750918274\n",
      "conv2W\n",
      "0.503684895833\n",
      "conv3W\n",
      "0.664001464844\n",
      "conv4W\n",
      "0.6518720462\n",
      "conv5W\n",
      "0.734985351562\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.005\n",
    "for layer in ['conv1W', 'conv2W', 'conv3W', 'conv4W', 'conv5W']:\n",
    "    print(layer)\n",
    "    print(np.mean(np.absolute(alexnet_weights[layer])<threshold))\n",
    "    \n",
    "for layer in ['conv1W', 'conv2W', 'conv3W', 'conv4W', 'conv5W']:\n",
    "    print(layer)\n",
    "    print(np.mean(np.absolute(e2e_weights[layer])<threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n, bins, patches = plt.hist(np.absolute(e2e_weights['conv3W']).flatten(),\\\n",
    "#                             40, facecolor='g', alpha=0.75)\n",
    "# plt.xlabel('Absolute Weight')\n",
    "# plt.ylabel('Proportion')\n",
    "# plt.title('Conv1 Weights')\n",
    "# # plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n",
    "# # plt.axis([40, 160, 0, 0.03])\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_true_class_saliency_comparison_samples(data_set, sample_list, tl_saliencies, e2e_saliencies, \n",
    "                                        fname, num_col_splits = 2):\n",
    "        \n",
    "    \n",
    "    f, axes = plt.subplots(len(sample_list)//num_col_splits, 3*num_col_splits, figsize=(80,26))\n",
    "    plt.subplots_adjust(wspace=0.02, hspace = 0.02)\n",
    "    col_splits = [0+i*3 for i in range(num_col_splits)]\n",
    "    \n",
    "#     from matplotlib import rcParams\n",
    "#     rcParams['axes.titlepad'] = 20 \n",
    "    \n",
    "    for col in col_splits:\n",
    "        axes[0][col].set_title(\"Original Image\", fontsize=45)\n",
    "        axes[0][col].title.set_position([.5, 1.02])\n",
    "        axes[0][col+1].set_title(\"Transfer Learning\", fontsize=45)\n",
    "        axes[0][col+1].title.set_position([.5, 1.02])\n",
    "        axes[0][col+2].set_title(\"End-to-end Learning\", fontsize=45)\n",
    "        axes[0][col+2].title.set_position([.5, 1.02])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    actor_count = 0\n",
    "    for col in col_splits:\n",
    "        for row in range(len(sample_list)//len(col_splits)):\n",
    "            actor, index = sample_list[actor_count]\n",
    "            axes[row][col].axis('off')\n",
    "            axes[row][col].imshow(data_set[actor][index].astype('uint8'))\n",
    "            \n",
    "            axes[row][col+1].axis('off')\n",
    "            axes[row][col+1].imshow(tl_saliencies[actor][index])\n",
    "            \n",
    "            axes[row][col+2].axis('off')\n",
    "            axes[row][col+2].imshow(e2e_saliencies[actor][index])\n",
    "            \n",
    "            actor_count += 1\n",
    "        \n",
    "    plt.savefig('weight comparison/' + fname +'.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# samples\n",
    "# samples = {'Anne Hathaway': [2,5,7], 'Jennifer Aniston':[1,2,14], 'America Ferrera':[0,4,14],\n",
    "#           'Nicolas Cage':[1,3,12], 'Gerard Butler':[3,7,14], 'Daniel Radcliffe':[2,13,14]}\n",
    "# samples = {'America Ferrera':[0,4,14], 'Gerard Butler':[3,7,14]}\n",
    "samples = {'America Ferrera':[0,14], 'Gerard Butler':[3,14]}\n",
    "sample_list = []\n",
    "for actor in samples:\n",
    "    for index in samples[actor]:\n",
    "        sample_list.append((actor, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('weight comparison/tl_saliency_robust_detail.pkl', 'rb') as handle:\n",
    "    tl_saliencies = _pickle.load(handle)\n",
    "with open('weight comparison/e2e_saliency_robust_detail.pkl', 'rb') as handle:\n",
    "    e2e_saliencies = _pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_true_class_saliency_comparison_samples(data_set, sample_list, tl_saliencies, e2e_saliencies, 'tl_vs_e2e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# good_exps = [('Daniel Radcliffe', 0), ('Daniel Radcliffe', 3), ('Anne Hathaway', 5), ('Anne Hathaway', 7),\n",
    "#              ('Angie Harmon', 1), ('Angie Harmon', 14), ('Fran Drescher', 4), ('Fran Drescher', 2)]\n",
    "# bad_exps = [('Jennifer Aniston', 1), ('Jennifer Aniston', 2), ('Bill Hader', 2), ('Bill Hader', 3)]\n",
    "\n",
    "# num_col_splits = 2\n",
    "\n",
    "\n",
    "# fname = 'good_exps'\n",
    "\n",
    "\n",
    "# f, axes = plt.subplots(len(good_exps)//2, 2*num_col_splits, figsize=(65,65))\n",
    "\n",
    "# plt.subplots_adjust(wspace=0.02, hspace = 0.02)\n",
    "# col_splits = [0+i*2 for i in range(num_col_splits)]\n",
    "# sample_list = good_exps\n",
    "# #     from matplotlib import rcParams\n",
    "# #     rcParams['axes.titlepad'] = 20 \n",
    "\n",
    "# for col in col_splits:\n",
    "#     axes[0][col].set_title(\"Original Image\", fontsize=45)\n",
    "#     axes[0][col+1].set_title(\"Saliency Map\", fontsize=45)\n",
    "\n",
    "# actor_count = 0\n",
    "# for col in col_splits:\n",
    "#     for row in range(len(sample_list)//len(col_splits)):\n",
    "#         actor, index = sample_list[actor_count]\n",
    "#         axes[row][col].axis('off')\n",
    "#         axes[row][col].imshow(data_set[actor][index].astype('uint8'))\n",
    "\n",
    "#         axes[row][col+1].axis('off')\n",
    "#         axes[row][col+1].imshow(e2e_saliencies[actor][index])\n",
    "\n",
    "#         actor_count += 1\n",
    "\n",
    "# plt.savefig('weight comparison/' + fname +'.png', bbox_inches='tight')\n",
    "# plt.close()\n",
    "\n",
    "    \n",
    "# fname = 'bad_exps'\n",
    "# f, axes = plt.subplots(len(bad_exps)//2, 2*num_col_splits, figsize=(65,32.5))\n",
    "# plt.subplots_adjust(wspace=0.02, hspace = 0.02)\n",
    "# col_splits = [0+i*2 for i in range(num_col_splits)]\n",
    "# sample_list = bad_exps\n",
    "# #     from matplotlib import rcParams\n",
    "# #     rcParams['axes.titlepad'] = 20 \n",
    "\n",
    "# for col in col_splits:\n",
    "#     axes[0][col].set_title(\"Original Image\", fontsize=45)\n",
    "#     axes[0][col+1].set_title(\"Saliency Map\", fontsize=45)\n",
    "\n",
    "# actor_count = 0\n",
    "# for col in col_splits:\n",
    "#     for row in range(len(sample_list)//len(col_splits)):\n",
    "#         actor, index = sample_list[actor_count]\n",
    "#         axes[row][col].axis('off')\n",
    "#         axes[row][col].imshow(data_set[actor][index].astype('uint8'))\n",
    "\n",
    "#         axes[row][col+1].axis('off')\n",
    "#         axes[row][col+1].imshow(e2e_saliencies[actor][index])\n",
    "\n",
    "#         actor_count += 1\n",
    "\n",
    "# plt.savefig('weight comparison/' + fname +'.png', bbox_inches='tight')\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exps = [('Daniel Radcliffe', 0), ('Angie Harmon', 1), ('Anne Hathaway', 5), ('Fran Drescher', 2), \n",
    "        ('Jennifer Aniston', 1), ('Bill Hader', 3)]\n",
    "\n",
    "num_col_splits = 3\n",
    "\n",
    "\n",
    "fname = 'exps'\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(len(exps)//num_col_splits, 2*num_col_splits, figsize=(80,26))\n",
    "\n",
    "plt.subplots_adjust(wspace=0.02, hspace = 0.02)\n",
    "col_splits = [0+i*2 for i in range(num_col_splits)]\n",
    "sample_list = exps\n",
    "#     from matplotlib import rcParams\n",
    "#     rcParams['axes.titlepad'] = 20 \n",
    "\n",
    "for col in col_splits:\n",
    "    axes[0][col].set_title(\"Original Image\", fontsize=45)\n",
    "    axes[0][col].title.set_position([.5, 1.02])\n",
    "    axes[0][col+1].set_title(\"Saliency Map\", fontsize=45)\n",
    "    axes[0][col+1].title.set_position([.5, 1.02])\n",
    "\n",
    "actor_count = 0\n",
    "for col in col_splits:\n",
    "    for row in range(len(sample_list)//len(col_splits)):\n",
    "        actor, index = sample_list[actor_count]\n",
    "        axes[row][col].axis('off')\n",
    "        axes[row][col].imshow(data_set[actor][index].astype('uint8'))\n",
    "\n",
    "        axes[row][col+1].axis('off')\n",
    "        axes[row][col+1].imshow(e2e_saliencies[actor][index])\n",
    "\n",
    "        actor_count += 1\n",
    "\n",
    "plt.savefig('weight comparison/' + fname +'.pdf', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_all_saliency_samples(e2e_saliencies):\n",
    "    \n",
    "    # save saliencies in an external array\n",
    "    saliency_masked = {}\n",
    "    for actor in data_set:\n",
    "        saliency_masked[actor] = np.zeros((0,227,227,3))\n",
    "    \n",
    "    \n",
    "    plt.figure(dpi=70, figsize=(140, 100))\n",
    "    col=0\n",
    "    for actor in data_set:\n",
    "        row = 0 \n",
    "        for _ in range(len(data_set[actor])):\n",
    "            \n",
    "            # forward pass\n",
    "            image = data_set[actor][_].astype(np.float64)\n",
    "            image_feed = np.expand_dims(image,0)\n",
    "            probabilities = sess.run(graph.probabilities, feed_dict={graph.inputs:image_feed})[0]\n",
    "    \n",
    "            # plot original image\n",
    "            index = row*len(data_set)*2 + col +1\n",
    "            plt.subplots_adjust(bottom = 0., wspace=0.15, hspace = 0.1, top=0.5)\n",
    "            plt.subplot(len(data_set[actor]), len(data_set)*2, index)\n",
    "            plt.axis('off')\n",
    "            plt.title(\"True: \" + actor + \"\\n Pred: \" + actor_code[np.argmax(probabilities)], fontsize=10)\n",
    "            plt.imshow(image.astype('uint8'))\n",
    "    \n",
    "            # plot true class_saliency\n",
    "            i = reversed_actor_code[actor]\n",
    "            one_hot = np.zeros(len(actor_code))\n",
    "            one_hot[i] = 1\n",
    "            plt.subplot(len(data_set[actor]), len(data_set)*2, index+1)\n",
    "            plt.axis('off')\n",
    "            plt.title(actor + '\\n' + str(probabilities[i]), fontsize=14)\n",
    "            detailed_saliency = guided_backprop(graph, image, one_hot, sess)\n",
    "            saliency = np.sum(detailed_saliency, axis=-1)\n",
    "            saliency_rank = saliency.ravel().argsort().argsort().reshape(saliency.shape)\n",
    "            saliency_mask = (saliency_rank > 227*227*0.95).astype(float)\n",
    "            masked_saliency = np.expand_dims(saliency_mask, axis=-1)*detailed_saliency\n",
    "            \n",
    "            plt.imshow(masked_saliency)\n",
    "\n",
    "            saliency_masked[actor] = np.vstack((saliency_masked[actor], np.expand_dims(masked_saliency, axis=0)))\n",
    "            saliency_masks[actor] = np.vstack((saliency_masks[actor], np.expand_dims(saliency_mask, axis=0)))\n",
    "            row += 1\n",
    "        col += 2\n",
    "    plt.savefig(fname +'.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    pickle_out = open(fname +\".pkl\",\"wb\")\n",
    "    _pickle.dump(saliency_masked, pickle_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_all_saliency_samples(actor, data_set, e2e_saliencies, num_col_splits = 3):\n",
    "        \n",
    "    \n",
    "    f, axes = plt.subplots(5, 2*num_col_splits, figsize=(80,70))\n",
    "    plt.subplots_adjust(wspace=0.02, hspace = 0.02)\n",
    "    col_splits = [0+i*2 for i in range(num_col_splits)]\n",
    "    \n",
    "#     from matplotlib import rcParams\n",
    "#     rcParams['axes.titlepad'] = 20 \n",
    "    \n",
    "#     for col in col_splits:\n",
    "#         axes[0][col].set_title(\"Original Image\", fontsize=45)\n",
    "#         axes[0][col].title.set_position([.5, 1.02])\n",
    "#         axes[0][col+1].set_title(\"Transfer Learning\", fontsize=45)\n",
    "#         axes[0][col+1].title.set_position([.5, 1.02])\n",
    "#         axes[0][col+2].set_title(\"End-to-end Learning\", fontsize=45)\n",
    "#         axes[0][col+2].title.set_position([.5, 1.02])\n",
    "\n",
    "    \n",
    "    index = 0\n",
    "    for col in col_splits:\n",
    "        for row in range(5):\n",
    "#             actor, index = sample_list[actor_count]\n",
    "            axes[row][col].axis('off')\n",
    "            axes[row][col].imshow(data_set[actor][index].astype('uint8'))\n",
    "            \n",
    "            axes[row][col+1].axis('off')\n",
    "            axes[row][col+1].imshow(e2e_saliencies[actor][index])\n",
    "            \n",
    "            index += 1\n",
    "        \n",
    "    plt.savefig('weight comparison/' + actor +'.pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for actor in data_set:\n",
    "    generate_all_saliency_samples(actor, data_set, e2e_saliencies, num_col_splits = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
