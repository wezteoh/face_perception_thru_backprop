{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import _pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# todo\n",
    "# compare likelihoods\n",
    "# test with less popular features\n",
    "# use different priors\n",
    "# multiclass logistic regression significance tests\n",
    "# fit mixture of gaussian vs gaussian\n",
    "# check if weight activity killed\n",
    "# tansfer learning for new class and robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('mean_diff_saliencies_vanilla_temp1.pkl', \"rb\")\n",
    "mean_diff_saliencies = _pickle.load(file) \n",
    "file = open('mean.pkl', \"rb\")\n",
    "gaussian_means = _pickle.load(file) \n",
    "file = open('covariance.pkl', \"rb\")\n",
    "gaussian_covariances = _pickle.load(file)\n",
    "\n",
    "with open('turker_prob.pkl', \"rb\") as handle:\n",
    "    turkers = _pickle.load(handle) \n",
    "\n",
    "with open('test_set_17_227.pkl', \"rb\") as handle:\n",
    "    test_set = _pickle.load(handle) \n",
    "    \n",
    "with open('turker_count.pkl', \"rb\") as handle:\n",
    "    turker_count= _pickle.load(handle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_actors = ['Daniel Radcliffe', 'Gerard Butler', 'Michael Vartan', 'Alec Baldwin', 'Steve Carell',\\\n",
    "                    'Bill Hader', 'Fran Drescher', 'Matt Damon', 'Nicolas Cage']\n",
    "female_actors = ['Cheryl Hines', 'Selena Gomez', 'Angie Harmon', 'Lorraine Bracco', 'Kristin Chenoweth',\\\n",
    "                      'America Ferrera', 'Anne Hathaway', 'Jennifer Aniston']\n",
    "gender ={}\n",
    "for actor in male_actors:\n",
    "    gender[actor] = 'male'\n",
    "for actor in female_actors:\n",
    "    gender[actor] = 'female' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating priors by gender\n",
    "features = ['beard','cheek', 'ears', 'eye brows', 'eyes', 'hairline', 'lips', 'moustache', 'nose']\n",
    "male_prior = {}\n",
    "for feature in features:\n",
    "    male_prior[feature] = 0\n",
    "for actor in male_actors:\n",
    "    for stats in turker_count[actor]:\n",
    "        for feature in features:\n",
    "            try:\n",
    "                male_prior[feature] += stats[feature]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "\n",
    "# creating priors by gender\n",
    "features = ['beard','cheek', 'ears', 'eye brows', 'eyes', 'hairline', 'lips', 'moustache', 'nose']\n",
    "female_prior = {}\n",
    "for feature in features:\n",
    "    female_prior[feature] = 0\n",
    "for actor in female_actors:\n",
    "    for stats in turker_count[actor]:\n",
    "        for feature in features:\n",
    "            try:\n",
    "                female_prior[feature] += stats[feature]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "\n",
    "prior = {}\n",
    "for feature in features:\n",
    "    prior[feature] = male_prior[feature] + female_prior[feature]\n",
    "\n",
    "total_count = sum(prior.values())\n",
    "for feature in prior:\n",
    "    prior[feature] /= total_count\n",
    "    \n",
    "total_count = sum(male_prior.values())\n",
    "for feature in male_prior:\n",
    "    male_prior[feature] /= total_count\n",
    "    \n",
    "total_count = sum(female_prior.values())\n",
    "for feature in female_prior:\n",
    "    female_prior[feature] /= total_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# monte carlo rectangles generation\n",
    "def generate_rectangles(means, covariances):\n",
    "    mc_samples = {}\n",
    "    for feature in sorted(means.keys()):\n",
    "#         print(feature)\n",
    "        rectangles = []\n",
    "        while len(rectangles) < 100:\n",
    "#             print(len(rectangles))\n",
    "            width, height, y_centre, x_centre = np.random.multivariate_normal(means[feature], \\\n",
    "                                                                              covariances[feature])\n",
    "            x_0= int(np.round(x_centre - width/2)) \n",
    "            x_1= int(np.round(x_centre + width/2)) \n",
    "            y_0= int(np.round(226 - y_centre - height/2)) \n",
    "            y_1= int(np.round(226 - y_centre + height/2)) \n",
    "            \n",
    "#             x_0= int(np.round(x_centre - height/2)) \n",
    "#             x_1= int(np.round(x_centre + height/2)) \n",
    "#             y_0= int(np.round(y_centre - width/2)) \n",
    "#             y_1= int(np.round(y_centre + width/2)) \n",
    "            \n",
    "#             print(np.array([x_centre, y_centre, height, width]))\n",
    "#             print(np.array([x_0,x_1,y_0,y_1]))\n",
    "            if 0<= x_0 < x_1 <=226 and 0<= y_0 < y_1 <=226:\n",
    "                rectangles.append(np.array([x_0,x_1,y_0,y_1]))\n",
    "                \n",
    "        mc_samples[feature] = np.stack(rectangles)\n",
    "        \n",
    "    return mc_samples \n",
    "\n",
    "mc_rectangle_samples = generate_rectangles(gaussian_means, gaussian_covariances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def likelihood(rectangles, saliency_map):\n",
    "    scores = {}\n",
    "    for feature in sorted(rectangles.keys()):\n",
    "        intensity_ratio_sum = 0\n",
    "        for rec in rectangles[feature]:\n",
    "            highlight = saliency_map[rec[2]:rec[3], rec[0]:rec[1]]\n",
    "            intensity_ratio = np.sum(highlight)/np.sum(saliency_map)\n",
    "            intensity_ratio_sum += intensity_ratio\n",
    "        scores[feature] = intensity_ratio_sum/len(rectangles[feature])\n",
    "    \n",
    "    sum_scores = np.sum(np.array(list(scores.values())))\n",
    "    probs = {}\n",
    "    \n",
    "    for feature in sorted(scores.keys()):\n",
    "        probs[feature] = scores[feature]/sum_scores\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def posterior(rectangles, saliency_map):\n",
    "    scores = {}\n",
    "    for feature in sorted(rectangles.keys()):\n",
    "        intensity_ratio_sum = 0\n",
    "        for rec in rectangles[feature]:\n",
    "            highlight = saliency_map[rec[2]:rec[3], rec[0]:rec[1],:]\n",
    "            intensity_ratio = np.sum(highlight)/np.sum(saliency_map)\n",
    "            intensity_ratio_sum += intensity_ratio\n",
    "        scores[feature] = prior[feature]*intensity_ratio_sum/len(rectangles[feature])\n",
    "    \n",
    "    sum_scores = np.sum(np.array(list(scores.values())))\n",
    "    probs = {}\n",
    "    \n",
    "    for feature in sorted(scores.keys()):\n",
    "        probs[feature] = scores[feature]/sum_scores\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gender_posterior(rectangles, saliency_map, gender):\n",
    "    scores = {}\n",
    "    for feature in sorted(rectangles.keys()):\n",
    "        intensity_ratio_sum = 0\n",
    "        for rec in rectangles[feature]:\n",
    "            highlight = saliency_map[rec[2]:rec[3], rec[0]:rec[1],:]\n",
    "            intensity_ratio = np.sum(highlight)/np.sum(saliency_map)\n",
    "            intensity_ratio_sum += intensity_ratio\n",
    "        if gender == 'male':\n",
    "            scores[feature] = male_prior[feature]*intensity_ratio_sum/len(rectangles[feature])\n",
    "        else:\n",
    "            scores[feature] = female_prior[feature]*intensity_ratio_sum/len(rectangles[feature])\n",
    "        \n",
    "    sum_scores = np.sum(np.array(list(scores.values())))\n",
    "    probs = {}\n",
    "    \n",
    "    for feature in sorted(scores.keys()):\n",
    "        probs[feature] = scores[feature]/sum_scores\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('true_class_saliency_mask_vanilla_temp1.pkl', \"rb\") as handle:\n",
    "    true_saliencies = _pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for actor in sorted(true_saliencies.keys()):\n",
    "    predictions[actor]=[]\n",
    "    for saliency_map in true_saliencies[actor]:\n",
    "        probs = likelihood(mc_rectangle_samples, saliency_map)\n",
    "        predictions[actor].append(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(turker_count['Alec Baldwin'][0].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beard\n",
      "[[ 9.8676597]]\n",
      "0.993710691824\n",
      "cheek\n",
      "[[ 35.85496214]]\n",
      "0.96750524109\n",
      "ears\n",
      "[[-38.05752279]]\n",
      "0.986373165618\n",
      "eye brows\n",
      "[[ 5.63606545]]\n",
      "0.842417889588\n",
      "eyes\n",
      "[[ 1.91820747]]\n",
      "0.69357092942\n",
      "hairline\n",
      "[[ 6.72577291]]\n",
      "0.88679245283\n",
      "lips\n",
      "[[-9.93463328]]\n",
      "0.895178197065\n",
      "moustache\n",
      "[[ 48.20494796]]\n",
      "0.957023060797\n",
      "nose\n",
      "[[-1.20847042]]\n",
      "0.777428371768\n"
     ]
    }
   ],
   "source": [
    "# create data bank for male and female respectively\n",
    "feature_index = {}\n",
    "\n",
    "        \n",
    "male_X = []\n",
    "male_Y = []\n",
    "\n",
    "for _ in range(len(features)):\n",
    "    feature_index[features[_]] = _\n",
    "\n",
    "for actor in male_actors:\n",
    "    for i in range(len(turker_count[actor])):\n",
    "        stat = turker_count[actor][i]\n",
    "        for feature in stat:\n",
    "            for _ in range(stat[feature]):\n",
    "                male_X.append(np.array([predictions[actor][i][f] for f in features]))\n",
    "#                 temp = np.zeros(len(features))\n",
    "#                 temp[feature_index[feature]]=1  \n",
    "                male_Y.append(feature_index[feature])\n",
    "\n",
    "\n",
    "male_X = np.stack(male_X)\n",
    "male_Y = np.stack(male_Y)\n",
    "\n",
    "for i in range(len(features)):\n",
    "    male_x = male_X[:,i].reshape(-1, 1)\n",
    "    male_y = male_Y == i\n",
    "    male_lr_model = LogisticRegression(fit_intercept=True, C = 1E10, multi_class='ovr', solver ='lbfgs')\n",
    "    male_lr_model_trained = male_lr_model.fit(male_x, male_y)\n",
    "    print(features[i])\n",
    "    print(male_lr_model_trained.coef_)\n",
    "    print(male_lr_model.score(male_x, male_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cheek\n",
      "[[ 13.77238665]]\n",
      "0.896270895842\n",
      "ears\n",
      "[[ 40.92372163]]\n",
      "0.99528504072\n",
      "eye brows\n",
      "[[ 17.1783579]]\n",
      "0.983711958851\n",
      "eyes\n",
      "[[ 0.77953032]]\n",
      "0.629661380197\n",
      "hairline\n",
      "[[ 11.25139524]]\n",
      "0.984569224175\n",
      "lips\n",
      "[[ 1.19336452]]\n",
      "0.759965709387\n",
      "moustache\n",
      "[[-88.28419995]]\n",
      "0.999571367338\n",
      "nose\n",
      "[[-5.54695607]]\n",
      "0.750964423489\n"
     ]
    }
   ],
   "source": [
    "# create data bank for male and female respectively\n",
    "feature_index = {}\n",
    "\n",
    "        \n",
    "female_X = []\n",
    "female_Y = []\n",
    "\n",
    "for _ in range(len(features)):\n",
    "    feature_index[features[_]] = _\n",
    "\n",
    "for actor in female_actors:\n",
    "    for i in range(len(turker_count[actor])):\n",
    "        stat = turker_count[actor][i]\n",
    "        for feature in stat:\n",
    "            for _ in range(stat[feature]):\n",
    "                female_X.append(np.array([predictions[actor][i][f] for f in features]))\n",
    "#                 temp = np.zeros(len(features))\n",
    "#                 temp[feature_index[feature]]=1  \n",
    "                female_Y.append(feature_index[feature])\n",
    "\n",
    "\n",
    "female_X = np.stack(female_X)\n",
    "female_Y = np.stack(female_Y)\n",
    "\n",
    "for i in range(1,len(features)):\n",
    "    female_x = female_X[:,i].reshape(-1, 1)\n",
    "    female_y = female_Y == i\n",
    "    female_lr_model = LogisticRegression(fit_intercept=True, C = 1E10, multi_class='ovr', solver ='lbfgs')\n",
    "    female_lr_model_trained = female_lr_model.fit(female_x, female_y)\n",
    "    print(features[i])\n",
    "    print(female_lr_model_trained.coef_)\n",
    "    print(female_lr_model.score(female_x, female_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beard',\n",
       " 'cheek',\n",
       " 'ears',\n",
       " 'eye brows',\n",
       " 'eyes',\n",
       " 'hairline',\n",
       " 'lips',\n",
       " 'moustache',\n",
       " 'nose']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_lr_model = LogisticRegression(fit_intercept=True, C = 1E10, multi_class='ovr', solver ='lbfgs')\n",
    "male_lr_model_trained = male_lr_model.fit(male_x, male_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 14.52022187]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_lr_model_trained.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_lr_model_trained.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beard': 0,\n",
       " 'cheek': 1,\n",
       " 'ears': 2,\n",
       " 'eye brows': 3,\n",
       " 'eyes': 4,\n",
       " 'hairline': 5,\n",
       " 'lips': 6,\n",
       " 'moustache': 7,\n",
       " 'nose': 8}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = open('flat_prior_predictions.pkl', 'wb')\n",
    "_pickle.dump(predictions, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posterior_predictions = {}\n",
    "for actor in sorted(mean_diff_saliencies.keys()):\n",
    "    posterior_predictions[actor]=[]\n",
    "    for saliency_map in mean_diff_saliencies[actor]:\n",
    "        probs = posterior(mc_rectangle_samples, saliency_map)\n",
    "        posterior_predictions[actor].append(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_posterior_predictions = {}\n",
    "for actor in sorted(mean_diff_saliencies.keys()):\n",
    "    gender_posterior_predictions[actor]=[]\n",
    "    for saliency_map in mean_diff_saliencies[actor]:\n",
    "        probs = gender_posterior(mc_rectangle_samples, saliency_map, gender[actor])\n",
    "        gender_posterior_predictions[actor].append(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec Baldwin\n",
      "America Ferrera\n",
      "Angie Harmon\n",
      "Anne Hathaway\n",
      "Bill Hader\n",
      "Cheryl Hines\n",
      "Daniel Radcliffe\n",
      "Fran Drescher\n",
      "Gerard Butler\n",
      "Jennifer Aniston\n",
      "Kristin Chenoweth\n",
      "Lorraine Bracco\n",
      "Matt Damon\n",
      "Michael Vartan\n",
      "Nicolas Cage\n",
      "Selena Gomez\n",
      "Steve Carell\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import operator\n",
    "\n",
    "folder = os.path.join('predictions','flat_prior','raw')\n",
    "\n",
    "count = 0\n",
    "for actor in sorted(test_set.keys()):\n",
    "    f, axes = plt.subplots(15, 3, figsize=(45,150))\n",
    "    for index in range(len(test_set[actor])):\n",
    "        \n",
    "        \n",
    "        ax = axes[index]\n",
    "        ax[0].axis('off')\n",
    "#         axes[0].set_size_inches(5, 5)\n",
    "        #      plt.title(\"overall actor saliency\", fontsize=14)\n",
    "        ax[0].imshow(test_set[actor][index].astype('uint8'))\n",
    "        \n",
    "        ax[1].axis('off')\n",
    "#         plt.title(\"overall actor saliency\", fontsize=14)\n",
    "#         axes[1].figure.set_size_inches(10, 10)\n",
    "        ax[1].imshow(mean_diff_saliencies[actor][index])\n",
    "        \n",
    "        prediction = predictions[actor][index]\n",
    "        turker_data = turkers[actor][index]\n",
    "\n",
    "        X = np.arange(len(prediction))\n",
    "        \n",
    "#         ax = plt.subplot(1,3,3)\n",
    "        sorted_prediction = sorted(prediction.items(), key=operator.itemgetter(1))\n",
    "        sorted_prediction.reverse()\n",
    "        \n",
    "        ax[2].bar(X, [prediction[key[0]] for key in sorted_prediction],\\\n",
    "               width=0.2, color='b', align='center', label='Prediction')\n",
    "        ax[2].bar(X-0.2, [turker_data[key[0]] for key in sorted_prediction],\\\n",
    "               width=0.2, color='g', align='center', label='Turkers')\n",
    "        ax[2].legend()\n",
    "        ax[2].set_xticks(X)\n",
    "        ax[2].set_xticklabels([key[0] for key in sorted_prediction])\n",
    "        ax[2].set_title(actor +\"_{}\".format(index), fontsize=17)\n",
    "    print(actor)\n",
    "    plt.savefig(os.path.join(folder, '{}.png'.format(count)))\n",
    "    count += 1\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec Baldwin\n",
      "America Ferrera\n",
      "Angie Harmon\n",
      "Anne Hathaway\n",
      "Bill Hader\n",
      "Cheryl Hines\n",
      "Daniel Radcliffe\n",
      "Fran Drescher\n",
      "Gerard Butler\n",
      "Jennifer Aniston\n",
      "Kristin Chenoweth\n",
      "Lorraine Bracco\n",
      "Matt Damon\n",
      "Michael Vartan\n",
      "Nicolas Cage\n",
      "Selena Gomez\n",
      "Steve Carell\n"
     ]
    }
   ],
   "source": [
    "folder = os.path.join('predictions','prior','raw')\n",
    "\n",
    "count = 0\n",
    "for actor in sorted(test_set.keys()):\n",
    "    f, axes = plt.subplots(15, 3, figsize=(45,150))\n",
    "    for index in range(len(test_set[actor])):\n",
    "        \n",
    "        \n",
    "        ax = axes[index]\n",
    "        ax[0].axis('off')\n",
    "#         axes[0].set_size_inches(5, 5)\n",
    "        #      plt.title(\"overall actor saliency\", fontsize=14)\n",
    "        ax[0].imshow(test_set[actor][index].astype('uint8'))\n",
    "        \n",
    "        ax[1].axis('off')\n",
    "#         plt.title(\"overall actor saliency\", fontsize=14)\n",
    "#         axes[1].figure.set_size_inches(10, 10)\n",
    "        ax[1].imshow(mean_diff_saliencies[actor][index])\n",
    "        \n",
    "        prediction = posterior_predictions[actor][index]\n",
    "        turker_data = turkers[actor][index]\n",
    "\n",
    "        X = np.arange(len(prediction))\n",
    "        \n",
    "#         ax = plt.subplot(1,3,3)\n",
    "        sorted_prediction = sorted(prediction.items(), key=operator.itemgetter(1))\n",
    "        sorted_prediction.reverse()\n",
    "        \n",
    "        ax[2].bar(X, [prediction[key[0]] for key in sorted_prediction],\\\n",
    "               width=0.2, color='b', align='center', label='Prediction')\n",
    "        ax[2].bar(X-0.2, [turker_data[key[0]] for key in sorted_prediction],\\\n",
    "               width=0.2, color='g', align='center', label='Turkers')\n",
    "        ax[2].legend()\n",
    "        ax[2].set_xticks(X)\n",
    "        ax[2].set_xticklabels([key[0] for key in sorted_prediction])\n",
    "        ax[2].set_title(actor +\"_{}\".format(index), fontsize=17)\n",
    "    print(actor)\n",
    "    plt.savefig(os.path.join(folder, '{}.png'.format(count)))\n",
    "    count += 1\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec Baldwin\n",
      "America Ferrera\n",
      "Angie Harmon\n",
      "Anne Hathaway\n",
      "Bill Hader\n",
      "Cheryl Hines\n",
      "Daniel Radcliffe\n",
      "Fran Drescher\n",
      "Gerard Butler\n",
      "Jennifer Aniston\n",
      "Kristin Chenoweth\n",
      "Lorraine Bracco\n",
      "Matt Damon\n",
      "Michael Vartan\n",
      "Nicolas Cage\n",
      "Selena Gomez\n",
      "Steve Carell\n"
     ]
    }
   ],
   "source": [
    "folder = os.path.join('predictions','gender_prior','raw')\n",
    "\n",
    "count = 0\n",
    "for actor in sorted(test_set.keys()):\n",
    "    f, axes = plt.subplots(15, 3, figsize=(45,150))\n",
    "    for index in range(len(test_set[actor])):\n",
    "        \n",
    "        \n",
    "        ax = axes[index]\n",
    "        ax[0].axis('off')\n",
    "#         axes[0].set_size_inches(5, 5)\n",
    "        #      plt.title(\"overall actor saliency\", fontsize=14)\n",
    "        ax[0].imshow(test_set[actor][index].astype('uint8'))\n",
    "        \n",
    "        ax[1].axis('off')\n",
    "#         plt.title(\"overall actor saliency\", fontsize=14)\n",
    "#         axes[1].figure.set_size_inches(10, 10)\n",
    "        ax[1].imshow(mean_diff_saliencies[actor][index])\n",
    "        \n",
    "        prediction = gender_posterior_predictions[actor][index]\n",
    "        turker_data = turkers[actor][index]\n",
    "\n",
    "        X = np.arange(len(prediction))\n",
    "        \n",
    "#         ax = plt.subplot(1,3,3)\n",
    "        sorted_prediction = sorted(prediction.items(), key=operator.itemgetter(1))\n",
    "        sorted_prediction.reverse()\n",
    "        \n",
    "        ax[2].bar(X, [prediction[key[0]] for key in sorted_prediction],\\\n",
    "               width=0.2, color='b', align='center', label='Prediction')\n",
    "        ax[2].bar(X-0.2, [turker_data[key[0]] for key in sorted_prediction],\\\n",
    "               width=0.2, color='g', align='center', label='Turkers')\n",
    "        ax[2].legend()\n",
    "        ax[2].set_xticks(X)\n",
    "        ax[2].set_xticklabels([key[0] for key in sorted_prediction])\n",
    "        ax[2].set_title(actor +\"_{}\".format(index), fontsize=17)\n",
    "    print(actor)\n",
    "    plt.savefig(os.path.join(folder, '{}.png'.format(count)))\n",
    "    count += 1\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec Baldwin\n",
      "America Ferrera\n",
      "Angie Harmon\n",
      "Anne Hathaway\n",
      "Bill Hader\n",
      "Cheryl Hines\n",
      "Daniel Radcliffe\n",
      "Fran Drescher\n",
      "Gerard Butler\n",
      "Jennifer Aniston\n",
      "Kristin Chenoweth\n",
      "Lorraine Bracco\n",
      "Matt Damon\n",
      "Michael Vartan\n",
      "Nicolas Cage\n",
      "Selena Gomez\n",
      "Steve Carell\n"
     ]
    }
   ],
   "source": [
    "folder = os.path.join('prior predictions','gender_prior','raw')\n",
    "\n",
    "count = 0\n",
    "for actor in sorted(test_set.keys()):\n",
    "    f, axes = plt.subplots(15, 3, figsize=(45,150))\n",
    "    for index in range(len(test_set[actor])):\n",
    "        \n",
    "        \n",
    "        ax = axes[index]\n",
    "        ax[0].axis('off')\n",
    "#         axes[0].set_size_inches(5, 5)\n",
    "        #      plt.title(\"overall actor saliency\", fontsize=14)\n",
    "        ax[0].imshow(test_set[actor][index].astype('uint8'))\n",
    "        \n",
    "        ax[1].axis('off')\n",
    "#         plt.title(\"overall actor saliency\", fontsize=14)\n",
    "#         axes[1].figure.set_size_inches(10, 10)\n",
    "        ax[1].imshow(mean_diff_saliencies[actor][index])\n",
    "        \n",
    "#         prediction = gender_posterior_predictions[actor][index]\n",
    "        turker_data = turkers[actor][index]\n",
    "\n",
    "       \n",
    "        \n",
    "#         ax = plt.subplot(1,3,3)\n",
    "        \n",
    "        if gender[actor] == 'male':\n",
    "            prediction = male_prior\n",
    "            sorted_prediction = sorted(male_prior.items(), key=operator.itemgetter(1))\n",
    "            \n",
    "        else:\n",
    "            prediction = female_prior\n",
    "            sorted_prediction = sorted(female_prior.items(), key=operator.itemgetter(1))\n",
    "            \n",
    "        sorted_prediction.reverse()\n",
    "        X = np.arange(len(prediction))\n",
    "        ax[2].bar(X, [prediction[key[0]] for key in sorted_prediction],\\\n",
    "               width=0.2, color='b', align='center', label='Prediction')\n",
    "        ax[2].bar(X-0.2, [turker_data[key[0]] for key in sorted_prediction],\\\n",
    "               width=0.2, color='g', align='center', label='Turkers')\n",
    "        ax[2].legend()\n",
    "        ax[2].set_xticks(X)\n",
    "        ax[2].set_xticklabels([key[0] for key in sorted_prediction])\n",
    "        ax[2].set_title(actor +\"_{}\".format(index), fontsize=17)\n",
    "    print(actor)\n",
    "    plt.savefig(os.path.join(folder, '{}.png'.format(count)))\n",
    "    count += 1\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beard': 0.006289308176100629,\n",
       " 'cheek': 0.03249475890985325,\n",
       " 'ears': 0.013626834381551363,\n",
       " 'eye brows': 0.15758211041229908,\n",
       " 'eyes': 0.30642907058001395,\n",
       " 'hairline': 0.11320754716981132,\n",
       " 'lips': 0.10482180293501048,\n",
       " 'moustache': 0.0429769392033543,\n",
       " 'nose': 0.2225716282320056}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beard': 0.0,\n",
       " 'cheek': 0.10372910415773683,\n",
       " 'ears': 0.004714959279897128,\n",
       " 'eye brows': 0.016288041148735534,\n",
       " 'eyes': 0.37033861980282895,\n",
       " 'hairline': 0.015430775825117874,\n",
       " 'lips': 0.2400342906129447,\n",
       " 'moustache': 0.0004286326618088298,\n",
       " 'nose': 0.24903557651093014}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slightly off: nose prior 0 for female?\n",
    "# new prior for likelihood estimation\n",
    "# use last three images of every actor as test set\n",
    "\n",
    "female_prior\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating priors by gender\n",
    "features = ['beard','cheek', 'ears', 'eye brows', 'eyes', 'hairline', 'lips', 'moustache', 'nose']\n",
    "male_prior = {}\n",
    "for feature in features:\n",
    "    male_prior[feature] = 0\n",
    "for actor in male_actors:\n",
    "    for stats in turker_count[actor][:10]:\n",
    "        for feature in features:\n",
    "            try:\n",
    "                male_prior[feature] += stats[feature]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "\n",
    "# creating priors by gender\n",
    "features = ['beard','cheek', 'ears', 'eye brows', 'eyes', 'hairline', 'lips', 'moustache', 'nose']\n",
    "female_prior = {}\n",
    "for feature in features:\n",
    "    female_prior[feature] = 0\n",
    "for actor in female_actors:\n",
    "    for stats in turker_count[actor][:10]:\n",
    "        for feature in features:\n",
    "            try:\n",
    "                female_prior[feature] += stats[feature]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "\n",
    "prior = {}\n",
    "for feature in features:\n",
    "    prior[feature] = male_prior[feature] + female_prior[feature]\n",
    "\n",
    "total_count = sum(prior.values())\n",
    "for feature in prior:\n",
    "    prior[feature] /= total_count\n",
    "    \n",
    "total_count = sum(male_prior.values())\n",
    "for feature in male_prior:\n",
    "    male_prior[feature] /= total_count\n",
    "    \n",
    "total_count = sum(female_prior.values())\n",
    "for feature in female_prior:\n",
    "    female_prior[feature] /= total_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for actor in sorted(mean_diff_saliencies.keys()):\n",
    "    predictions[actor]=[]\n",
    "    for saliency_map in mean_diff_saliencies[actor][10:]:\n",
    "        probs = likelihood(mc_rectangle_samples, saliency_map)\n",
    "        predictions[actor].append(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-likelihood -4521.20985944641\n",
      "accuracy 0.26985519964896887\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "# check likelihood and accuracy\n",
    "loglik = 0\n",
    "accurate_count = 0\n",
    "count = 0\n",
    "const  = 1E-20\n",
    "for actor in predictions:\n",
    "#     loglik = 0\n",
    "#     accurate_count = 0\n",
    "#     count = 0\n",
    "#     const  = 1E-20\n",
    "    for i in range(5):\n",
    "        prediction = predictions[actor][i]\n",
    "        order = sorted(prediction.items(), key=operator.itemgetter(1))\n",
    "        data = turker_count[actor][10+i]\n",
    "        for feature in prediction:\n",
    "            loglik += data[feature]*np.log(prediction[feature]+const)\n",
    "        \n",
    "        accurate_count +=  data[order[-1][0]]\n",
    "        count += sum(data.values())\n",
    "# print(actor)\n",
    "print('log-likelihood {}'.format(loglik))\n",
    "print('accuracy {}'.format(accurate_count/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_posterior_predictions = {}\n",
    "for actor in sorted(mean_diff_saliencies.keys()):\n",
    "    gender_posterior_predictions[actor]=[]\n",
    "    for saliency_map in mean_diff_saliencies[actor][10:]:\n",
    "        probs = gender_posterior(mc_rectangle_samples, saliency_map, gender[actor])\n",
    "        gender_posterior_predictions[actor].append(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-likelihood -4209.832192153892\n",
      "accuracy 0.31505046072838966\n"
     ]
    }
   ],
   "source": [
    "# check likelihood and accuracy\n",
    "loglik = 0\n",
    "accurate_count = 0\n",
    "count = 0\n",
    "const  = 1E-20\n",
    "for actor in gender_posterior_predictions:\n",
    "#     loglik = 0\n",
    "#     accurate_count = 0\n",
    "#     count = 0\n",
    "#     const  = 1E-20\n",
    "    for i in range(5):\n",
    "        prediction = gender_posterior_predictions[actor][i]\n",
    "        order = sorted(prediction.items(), key=operator.itemgetter(1))\n",
    "        data = turker_count[actor][10+i]\n",
    "        for feature in prediction:\n",
    "            loglik += data[feature]*np.log(prediction[feature]+const)\n",
    "        \n",
    "        accurate_count +=  data[order[-1][0]]\n",
    "        count += sum(data.values())\n",
    "# print(actor)\n",
    "print('log-likelihood {}'.format(loglik))\n",
    "print('accuracy {}'.format(accurate_count/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-likelihood -3837.1988471918185\n",
      "accuracy 0.3181219833260202\n"
     ]
    }
   ],
   "source": [
    "# check likelihood and accuracy\n",
    "loglik = 0\n",
    "accurate_count = 0\n",
    "count = 0\n",
    "const  = 1E-20\n",
    "for actor in gender_posterior_predictions:\n",
    "#     loglik = 0\n",
    "#     accurate_count = 0\n",
    "#     count = 0\n",
    "#     const  = 1E-20\n",
    "    for i in range(5):\n",
    "        if gender[actor] == 'male':\n",
    "            prediction = male_prior\n",
    "        else:\n",
    "            prediction = female_prior\n",
    "        order = sorted(prediction.items(), key=operator.itemgetter(1))\n",
    "        data = turker_count[actor][10+i]\n",
    "        for feature in prediction:\n",
    "            loglik += data[feature]*np.log(prediction[feature]+const)\n",
    "        \n",
    "        accurate_count +=  data[order[-1][0]]\n",
    "        count += sum(data.values())\n",
    "\n",
    "#     print(actor)\n",
    "print('log-likelihood {}'.format(loglik))\n",
    "print('accuracy {}'.format(accurate_count/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main problems are with turker data\n",
    "# maybe imbalanced, also tend to label similar feature\n",
    "# maybe should try new set of actors who have very distinct features to do anchoring\n",
    "# people choocse what seems to get highlighted in that image, but not what is salient about the person\n",
    "# probaly better to frame questionas as what is salient about this individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beard': 0.0043586550435865505,\n",
       " 'cheek': 0.03424657534246575,\n",
       " 'ears': 0.010585305105853052,\n",
       " 'eye brows': 0.14881693648816938,\n",
       " 'eyes': 0.3150684931506849,\n",
       " 'hairline': 0.11581569115815692,\n",
       " 'lips': 0.10336239103362391,\n",
       " 'moustache': 0.036737235367372355,\n",
       " 'nose': 0.23100871731008718}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beard': 0.0,\n",
       " 'cheek': 0.10610687022900764,\n",
       " 'ears': 0.0061068702290076335,\n",
       " 'eye brows': 0.01450381679389313,\n",
       " 'eyes': 0.3893129770992366,\n",
       " 'hairline': 0.010687022900763359,\n",
       " 'lips': 0.22900763358778625,\n",
       " 'moustache': 0.0007633587786259542,\n",
       " 'nose': 0.2435114503816794}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating priors by gender\n",
    "features = ['beard','cheek', 'ears', 'eye brows', 'eyes', 'hairline', 'lips', 'moustache', 'nose']\n",
    "male_prior = {}\n",
    "for feature in features:\n",
    "    male_prior[feature] = 0\n",
    "for actor in male_actors:\n",
    "    for stats in turker_count[actor]:\n",
    "        for feature in features:\n",
    "            try:\n",
    "                male_prior[feature] += stats[feature]\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "\n",
    "# creating priors by gender\n",
    "features = ['beard','cheek', 'ears', 'eye brows', 'eyes', 'hairline', 'lips', 'moustache', 'nose']\n",
    "female_prior = {}\n",
    "for feature in features:\n",
    "    female_prior[feature] = 0\n",
    "for actor in female_actors:\n",
    "    for stats in turker_count[actor]:\n",
    "        for feature in features:\n",
    "            try:\n",
    "                female_prior[feature] += stats[feature]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "\n",
    "prior = {}\n",
    "for feature in features:\n",
    "    prior[feature] = male_prior[feature] + female_prior[feature]\n",
    "\n",
    "total_count = sum(prior.values())\n",
    "for feature in prior:\n",
    "    prior[feature] /= total_count\n",
    "    \n",
    "total_count = sum(male_prior.values())\n",
    "for feature in male_prior:\n",
    "    male_prior[feature] /= total_count\n",
    "    \n",
    "total_count = sum(female_prior.values())\n",
    "for feature in female_prior:\n",
    "    female_prior[feature] /= total_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor_diff_saliencies = {}\n",
    "\n",
    "for actor in mean_diff_saliencies:\n",
    "    mean_diff = np.sum(mean_diff_saliencies[actor], axis=0)\n",
    "    mean_diff = mean_diff/np.max(mean_diff)\n",
    "    actor_diff_saliencies[actor] = mean_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor_posterior_predictions = {}\n",
    "for actor in sorted(actor_diff_saliencies.keys()):\n",
    "    probs = gender_posterior(mc_rectangle_samples, actor_diff_saliencies[actor], gender[actor])\n",
    "    actor_posterior_predictions[actor]=probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating turker coiunt per actor\n",
    "actor_stats = {}\n",
    "features = ['beard','cheek', 'ears', 'eye brows', 'eyes', 'hairline', 'lips', 'moustache', 'nose']\n",
    "for actor in actor_diff_saliencies:\n",
    "    actor_stats[actor] = {}\n",
    "    for feature in features:\n",
    "        actor_stats[actor][feature] = 0  \n",
    "    for stats in turker_count[actor]:\n",
    "        for feature in features:\n",
    "            try:\n",
    "                 actor_stats[actor][feature] += stats[feature]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "for actor in actor_stats:\n",
    "    total_count = sum(actor_stats[actor].values())\n",
    "    for feature in features:\n",
    "        actor_stats[actor][feature] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec Baldwin\n",
      "America Ferrera\n",
      "Angie Harmon\n",
      "Anne Hathaway\n",
      "Bill Hader\n",
      "Cheryl Hines\n",
      "Daniel Radcliffe\n",
      "Fran Drescher\n",
      "Gerard Butler\n",
      "Jennifer Aniston\n",
      "Kristin Chenoweth\n",
      "Lorraine Bracco\n",
      "Matt Damon\n",
      "Michael Vartan\n",
      "Nicolas Cage\n",
      "Selena Gomez\n",
      "Steve Carell\n"
     ]
    }
   ],
   "source": [
    "actors = sorted(test_set.keys())\n",
    "\n",
    "f, axes = plt.subplots(17, 3, figsize=(45,170))\n",
    "\n",
    "for i in range(len(actors)):\n",
    "    actor = actors[i]\n",
    "    ax = axes[i]\n",
    "\n",
    "    ax[0].set_title(actor)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].imshow(actor_diff_saliencies[actor])\n",
    "        \n",
    "      \n",
    "    turker_data = actor_stats[actor]\n",
    "    sorted_turker_data = sorted(turker_data.items(), key=operator.itemgetter(1))\n",
    "    sorted_turker_data.reverse()\n",
    "    \n",
    "    X = np.arange(len(turker_data))\n",
    "    ax[1].bar(X, [actor_posterior_predictions[actor][key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='b', align='center', label='Posterior Prediction')\n",
    "    ax[1].bar(X-0.2, [turker_data[key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='g', align='center', label='Turkers')\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xticks(X)\n",
    "    ax[1].set_xticklabels([key[0] for key in sorted_turker_data])\n",
    "    ax[1].set_title('posterior vs turkers', fontsize=17)\n",
    "    \n",
    "    \n",
    "    if gender[actor] == 'male':\n",
    "        prediction = male_prior\n",
    "\n",
    "    else:\n",
    "        prediction = female_prior\n",
    "\n",
    "    X = np.arange(len(turker_data))\n",
    "    ax[2].bar(X, [prediction[key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='b', align='center', label='Prior Prediction')\n",
    "    ax[2].bar(X-0.2, [turker_data[key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='g', align='center', label='Turkers')\n",
    "    ax[2].legend()\n",
    "    ax[2].set_xticks(X)\n",
    "    ax[2].set_xticklabels([key[0] for key in sorted_turker_data])\n",
    "    ax[2].set_title('prior vs turkers', fontsize=17)\n",
    "    print(actor)\n",
    "plt.savefig('actor_predictions.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor_bp_predictions = {}\n",
    "for actor in sorted(actor_diff_saliencies.keys()):\n",
    "    probs = likelihood(mc_rectangle_samples, actor_diff_saliencies[actor])\n",
    "    actor_bp_predictions[actor]=probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec Baldwin\n",
      "America Ferrera\n",
      "Angie Harmon\n",
      "Anne Hathaway\n",
      "Bill Hader\n",
      "Cheryl Hines\n",
      "Daniel Radcliffe\n",
      "Fran Drescher\n",
      "Gerard Butler\n",
      "Jennifer Aniston\n",
      "Kristin Chenoweth\n",
      "Lorraine Bracco\n",
      "Matt Damon\n",
      "Michael Vartan\n",
      "Nicolas Cage\n",
      "Selena Gomez\n",
      "Steve Carell\n"
     ]
    }
   ],
   "source": [
    "actors = sorted(test_set.keys())\n",
    "\n",
    "f, axes = plt.subplots(17, 3, figsize=(45,170))\n",
    "\n",
    "for i in range(len(actors)):\n",
    "    actor = actors[i]\n",
    "    ax = axes[i]\n",
    "\n",
    "    ax[0].set_title(actor)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].imshow(actor_diff_saliencies[actor])\n",
    "        \n",
    "      \n",
    "    turker_data = actor_stats[actor]\n",
    "    sorted_turker_data = sorted(turker_data.items(), key=operator.itemgetter(1))\n",
    "    sorted_turker_data.reverse()\n",
    "    \n",
    "    X = np.arange(len(turker_data))\n",
    "    ax[1].bar(X, [actor_bp_predictions[actor][key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='b', align='center', label='Posterior Prediction')\n",
    "    ax[1].bar(X-0.2, [turker_data[key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='g', align='center', label='Turkers')\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xticks(X)\n",
    "    ax[1].set_xticklabels([key[0] for key in sorted_turker_data])\n",
    "    ax[1].set_title('posterior vs turkers', fontsize=17)\n",
    "    \n",
    "#     if gender[actor] == 'male':\n",
    "#         prediction = male_prior\n",
    "\n",
    "#     else:\n",
    "#         prediction = female_prior\n",
    "\n",
    "    X = np.arange(len(turker_data))\n",
    "    ax[2].bar(X, [float(1/9) for key in sorted_turker_data],\\\n",
    "           width=0.2, color='b', align='center', label='Prior Prediction')\n",
    "    ax[2].bar(X-0.2, [turker_data[key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='g', align='center', label='Turkers')\n",
    "    ax[2].legend()\n",
    "    ax[2].set_xticks(X)\n",
    "    ax[2].set_xticklabels([key[0] for key in sorted_turker_data])\n",
    "    ax[2].set_title('prior vs turkers', fontsize=17)\n",
    "    print(actor)\n",
    "plt.savefig('actor_bp_predictions.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = open('actor_bp_predictions.pkl', 'wb')\n",
    "_pickle.dump(actor_bp_predictions, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec Baldwin\n",
      "SpearmanrResult(correlation=0.88148255470705361, pvalue=0.0016774219366218158)\n",
      "America Ferrera\n",
      "SpearmanrResult(correlation=0.84757937952601303, pvalue=0.0039085480832251867)\n",
      "Angie Harmon\n",
      "SpearmanrResult(correlation=0.77824949014282241, pvalue=0.013505972810006874)\n",
      "Anne Hathaway\n",
      "SpearmanrResult(correlation=0.6134670389756931, pvalue=0.078915226437158675)\n",
      "Bill Hader\n",
      "SpearmanrResult(correlation=0.94928890506913455, pvalue=9.2000228099956688e-05)\n",
      "Cheryl Hines\n",
      "SpearmanrResult(correlation=0.48535989707831934, pvalue=0.18535381786420974)\n",
      "Daniel Radcliffe\n",
      "SpearmanrResult(correlation=0.76666666666666672, pvalue=0.015944016578974009)\n",
      "Fran Drescher\n",
      "SpearmanrResult(correlation=0.72242227221614608, pvalue=0.027924260269707922)\n",
      "Gerard Butler\n",
      "SpearmanrResult(correlation=0.59999999999999998, pvalue=0.087622829041402395)\n",
      "Jennifer Aniston\n",
      "SpearmanrResult(correlation=0.71196667880185094, pvalue=0.031425255860766076)\n",
      "Kristin Chenoweth\n",
      "SpearmanrResult(correlation=0.55940239048716867, pvalue=0.11733810288497036)\n",
      "Lorraine Bracco\n",
      "SpearmanrResult(correlation=0.58582908655548527, pvalue=0.097398366840699413)\n",
      "Matt Damon\n",
      "SpearmanrResult(correlation=0.96666666666666667, pvalue=2.1550312748357751e-05)\n",
      "Michael Vartan\n",
      "SpearmanrResult(correlation=0.79999999999999993, pvalue=0.0096279247253798304)\n",
      "Nicolas Cage\n",
      "SpearmanrResult(correlation=0.76666666666666672, pvalue=0.015944016578974009)\n",
      "Selena Gomez\n",
      "SpearmanrResult(correlation=0.71196667880185094, pvalue=0.031425255860766076)\n",
      "Steve Carell\n",
      "SpearmanrResult(correlation=0.72271459386177539, pvalue=0.027830239887836096)\n",
      "correlation\n",
      "0.733513468601\n",
      "pvalue\n",
      "0.0438796944824\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "cors = []\n",
    "pvals = []\n",
    "for actor in sorted(test_set.keys()):\n",
    "    print(actor)\n",
    "    turker_data = actor_stats[actor]\n",
    "    sorted_turker_data = sorted(turker_data.items(), key=operator.itemgetter(1))\n",
    "    predicted = np.array([actor_bp_predictions[actor][key[0]] for key in sorted_turker_data])\n",
    "    turker = np.array([turker_data[key[0]] for key in sorted_turker_data])\n",
    "    cor, pval = spearmanr(predicted, turker) \n",
    "    cors.append(cor)\n",
    "    pvals.append(pval)\n",
    "    print(spearmanr(predicted, turker))\n",
    "print('correlation')\n",
    "print(np.mean(np.array(cors)))    \n",
    "print('pvalue')\n",
    "print(np.mean(np.array(pvals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('saliency_data17/true_class_saliency_vanilla_temp1.pkl', \"rb\") as handle:\n",
    "    true_saliencies = _pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor_saliencies = {}\n",
    "for actor in true_saliencies:\n",
    "    mean_true = np.sum(true_saliencies[actor], axis=0)\n",
    "    mean_true = mean_true/np.max(mean_true)\n",
    "    actor_saliencies[actor] = mean_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor_true_bp_predictions = {}\n",
    "for actor in sorted(actor_saliencies.keys()):\n",
    "    probs = likelihood(mc_rectangle_samples, actor_saliencies[actor])\n",
    "    actor_true_bp_predictions[actor]=probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec Baldwin\n",
      "America Ferrera\n",
      "Angie Harmon\n",
      "Anne Hathaway\n",
      "Bill Hader\n",
      "Cheryl Hines\n",
      "Daniel Radcliffe\n",
      "Fran Drescher\n",
      "Gerard Butler\n",
      "Jennifer Aniston\n",
      "Kristin Chenoweth\n",
      "Lorraine Bracco\n",
      "Matt Damon\n",
      "Michael Vartan\n",
      "Nicolas Cage\n",
      "Selena Gomez\n",
      "Steve Carell\n"
     ]
    }
   ],
   "source": [
    "actors = sorted(test_set.keys())\n",
    "\n",
    "f, axes = plt.subplots(17, 3, figsize=(45,170))\n",
    "\n",
    "for i in range(len(actors)):\n",
    "    actor = actors[i]\n",
    "    ax = axes[i]\n",
    "\n",
    "    ax[0].set_title(actor)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].imshow(actor_saliencies[actor])\n",
    "        \n",
    "      \n",
    "    turker_data = actor_stats[actor]\n",
    "    sorted_turker_data = sorted(turker_data.items(), key=operator.itemgetter(1))\n",
    "    sorted_turker_data.reverse()\n",
    "    \n",
    "    X = np.arange(len(turker_data))\n",
    "    ax[1].bar(X, [actor_true_bp_predictions[actor][key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='b', align='center', label='Posterior Prediction')\n",
    "    ax[1].bar(X-0.2, [turker_data[key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='g', align='center', label='Turkers')\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xticks(X)\n",
    "    ax[1].set_xticklabels([key[0] for key in sorted_turker_data])\n",
    "    ax[1].set_title('posterior vs turkers', fontsize=17)\n",
    "    \n",
    "#     if gender[actor] == 'male':\n",
    "#         prediction = male_prior\n",
    "\n",
    "#     else:\n",
    "#         prediction = female_prior\n",
    "\n",
    "    X = np.arange(len(turker_data))\n",
    "    ax[2].bar(X, [float(1/9) for key in sorted_turker_data],\\\n",
    "           width=0.2, color='b', align='center', label='Prior Prediction')\n",
    "    ax[2].bar(X-0.2, [turker_data[key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='g', align='center', label='Turkers')\n",
    "    ax[2].legend()\n",
    "    ax[2].set_xticks(X)\n",
    "    ax[2].set_xticklabels([key[0] for key in sorted_turker_data])\n",
    "    ax[2].set_title('prior vs turkers', fontsize=17)\n",
    "    print(actor)\n",
    "plt.savefig('actor_true_bp_predictions.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec Baldwin\n",
      "SpearmanrResult(correlation=0.93233731747861426, pvalue=0.00024822089814914041)\n",
      "America Ferrera\n",
      "SpearmanrResult(correlation=0.77977302916393199, pvalue=0.013205186732060017)\n",
      "Angie Harmon\n",
      "SpearmanrResult(correlation=0.77824949014282241, pvalue=0.013505972810006874)\n",
      "Anne Hathaway\n",
      "SpearmanrResult(correlation=0.6975036196572949, pvalue=0.036722324744514964)\n",
      "Bill Hader\n",
      "SpearmanrResult(correlation=0.93233731747861426, pvalue=0.00024822089814914041)\n",
      "Cheryl Hines\n",
      "SpearmanrResult(correlation=0.64435710474190677, pvalue=0.061032957699099791)\n",
      "Daniel Radcliffe\n",
      "SpearmanrResult(correlation=0.84999999999999987, pvalue=0.0037047773275858133)\n",
      "Fran Drescher\n",
      "SpearmanrResult(correlation=0.8616843969807042, pvalue=0.0028228814548817384)\n",
      "Gerard Butler\n",
      "SpearmanrResult(correlation=0.59999999999999998, pvalue=0.087622829041402395)\n",
      "Jennifer Aniston\n",
      "SpearmanrResult(correlation=0.72891826639237112, pvalue=0.025883597169560207)\n",
      "Kristin Chenoweth\n",
      "SpearmanrResult(correlation=0.72891826639237112, pvalue=0.025883597169560207)\n",
      "Lorraine Bracco\n",
      "SpearmanrResult(correlation=0.58582908655548527, pvalue=0.097398366840699413)\n",
      "Matt Damon\n",
      "SpearmanrResult(correlation=0.98333333333333328, pvalue=1.9361963037459243e-06)\n",
      "Michael Vartan\n",
      "SpearmanrResult(correlation=0.79999999999999993, pvalue=0.0096279247253798304)\n",
      "Nicolas Cage\n",
      "SpearmanrResult(correlation=0.81666666666666665, pvalue=0.0072247852463587859)\n",
      "Selena Gomez\n",
      "SpearmanrResult(correlation=0.81367620434497245, pvalue=0.007621974237534971)\n",
      "Steve Carell\n",
      "SpearmanrResult(correlation=0.67229264545281431, pvalue=0.047274938290474543)\n",
      "correlation\n",
      "0.776816279105\n",
      "pvalue\n",
      "0.0258841465577\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "cors = []\n",
    "pvals = []\n",
    "for actor in sorted(test_set.keys()):\n",
    "    print(actor)\n",
    "    turker_data = actor_stats[actor]\n",
    "    sorted_turker_data = sorted(turker_data.items(), key=operator.itemgetter(1))\n",
    "    predicted = np.array([actor_true_bp_predictions[actor][key[0]] for key in sorted_turker_data])\n",
    "    turker = np.array([turker_data[key[0]] for key in sorted_turker_data])\n",
    "    cor, pval = spearmanr(predicted, turker) \n",
    "    cors.append(cor)\n",
    "    pvals.append(pval)\n",
    "    print(spearmanr(predicted, turker))\n",
    "\n",
    "print('correlation')\n",
    "print(np.mean(np.array(cors)))    \n",
    "print('pvalue')\n",
    "print(np.mean(np.array(pvals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('true_class_saliency_mask_vanilla_temp1.pkl', \"rb\") as handle:\n",
    "    true_saliencies = _pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor_saliencies = {}\n",
    "for actor in true_saliencies:\n",
    "    mean_true = np.sum(true_saliencies[actor], axis=0)\n",
    "    mean_true = mean_true/np.max(mean_true)\n",
    "    actor_saliencies[actor] = mean_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def likelihood(rectangles, saliency_map):\n",
    "    scores = {}\n",
    "    for feature in sorted(rectangles.keys()):\n",
    "        intensity_ratio_sum = 0\n",
    "        for rec in rectangles[feature]:\n",
    "            highlight = saliency_map[rec[2]:rec[3], rec[0]:rec[1]]\n",
    "            intensity_ratio = np.sum(highlight)/np.sum(saliency_map)\n",
    "            intensity_ratio_sum += intensity_ratio\n",
    "        scores[feature] = intensity_ratio_sum/len(rectangles[feature])\n",
    "    \n",
    "    sum_scores = np.sum(np.array(list(scores.values())))\n",
    "    probs = {}\n",
    "    \n",
    "    for feature in sorted(scores.keys()):\n",
    "        probs[feature] = scores[feature]/sum_scores\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor_true_bp_predictions = {}\n",
    "for actor in sorted(actor_saliencies.keys()):\n",
    "    probs = likelihood(mc_rectangle_samples, actor_saliencies[actor])\n",
    "    actor_true_bp_predictions[actor]=probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec Baldwin\n",
      "America Ferrera\n",
      "Angie Harmon\n",
      "Anne Hathaway\n",
      "Bill Hader\n",
      "Cheryl Hines\n",
      "Daniel Radcliffe\n",
      "Fran Drescher\n",
      "Gerard Butler\n",
      "Jennifer Aniston\n",
      "Kristin Chenoweth\n",
      "Lorraine Bracco\n",
      "Matt Damon\n",
      "Michael Vartan\n",
      "Nicolas Cage\n",
      "Selena Gomez\n",
      "Steve Carell\n"
     ]
    }
   ],
   "source": [
    "actors = sorted(test_set.keys())\n",
    "\n",
    "f, axes = plt.subplots(17, 3, figsize=(45,170))\n",
    "\n",
    "for i in range(len(actors)):\n",
    "    actor = actors[i]\n",
    "    ax = axes[i]\n",
    "\n",
    "    ax[0].set_title(actor)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].imshow(actor_saliencies[actor])\n",
    "        \n",
    "      \n",
    "    turker_data = actor_stats[actor]\n",
    "    sorted_turker_data = sorted(turker_data.items(), key=operator.itemgetter(1))\n",
    "    sorted_turker_data.reverse()\n",
    "    \n",
    "    X = np.arange(len(turker_data))\n",
    "    ax[1].bar(X, [actor_true_bp_predictions[actor][key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='b', align='center', label='Posterior Prediction')\n",
    "    ax[1].bar(X-0.2, [turker_data[key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='g', align='center', label='Turkers')\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xticks(X)\n",
    "    ax[1].set_xticklabels([key[0] for key in sorted_turker_data])\n",
    "    ax[1].set_title('posterior vs turkers', fontsize=17)\n",
    "    \n",
    "#     if gender[actor] == 'male':\n",
    "#         prediction = male_prior\n",
    "\n",
    "#     else:\n",
    "#         prediction = female_prior\n",
    "\n",
    "    X = np.arange(len(turker_data))\n",
    "    ax[2].bar(X, [float(1/9) for key in sorted_turker_data],\\\n",
    "           width=0.2, color='b', align='center', label='Prior Prediction')\n",
    "    ax[2].bar(X-0.2, [turker_data[key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='g', align='center', label='Turkers')\n",
    "    ax[2].legend()\n",
    "    ax[2].set_xticks(X)\n",
    "    ax[2].set_xticklabels([key[0] for key in sorted_turker_data])\n",
    "    ax[2].set_title('prior vs turkers', fontsize=17)\n",
    "    print(actor)\n",
    "plt.savefig('actor_true_bp_predictions.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec Baldwin\n",
      "SpearmanrResult(correlation=0.93233731747861426, pvalue=0.00024822089814914041)\n",
      "America Ferrera\n",
      "SpearmanrResult(correlation=0.84757937952601303, pvalue=0.0039085480832251867)\n",
      "Angie Harmon\n",
      "SpearmanrResult(correlation=0.76151294196770791, pvalue=0.017117125525800674)\n",
      "Anne Hathaway\n",
      "SpearmanrResult(correlation=0.6975036196572949, pvalue=0.036722324744514964)\n",
      "Bill Hader\n",
      "SpearmanrResult(correlation=0.93233731747861426, pvalue=0.00024822089814914041)\n",
      "Cheryl Hines\n",
      "SpearmanrResult(correlation=0.74477639379259353, pvalue=0.021319728123320163)\n",
      "Daniel Radcliffe\n",
      "SpearmanrResult(correlation=0.90000000000000002, pvalue=0.00094306232234032928)\n",
      "Fran Drescher\n",
      "SpearmanrResult(correlation=0.8616843969807042, pvalue=0.0028228814548817384)\n",
      "Gerard Butler\n",
      "SpearmanrResult(correlation=0.66666666666666674, pvalue=0.049867230568885111)\n",
      "Jennifer Aniston\n",
      "SpearmanrResult(correlation=0.72891826639237112, pvalue=0.025883597169560207)\n",
      "Kristin Chenoweth\n",
      "SpearmanrResult(correlation=0.7628214415734117, pvalue=0.016814014277908546)\n",
      "Lorraine Bracco\n",
      "SpearmanrResult(correlation=0.58582908655548527, pvalue=0.097398366840699413)\n",
      "Matt Damon\n",
      "SpearmanrResult(correlation=0.98333333333333328, pvalue=1.9361963037459243e-06)\n",
      "Michael Vartan\n",
      "SpearmanrResult(correlation=0.79999999999999993, pvalue=0.0096279247253798304)\n",
      "Nicolas Cage\n",
      "SpearmanrResult(correlation=0.81666666666666665, pvalue=0.0072247852463587859)\n",
      "Selena Gomez\n",
      "SpearmanrResult(correlation=0.77977302916393199, pvalue=0.013205186732060017)\n",
      "Steve Carell\n",
      "SpearmanrResult(correlation=0.80675117454337719, pvalue=0.0085980832665393907)\n",
      "correlation\n",
      "0.800499472457\n",
      "pvalue\n",
      "0.0183500727691\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "cors = []\n",
    "pvals = []\n",
    "for actor in sorted(test_set.keys()):\n",
    "    print(actor)\n",
    "    turker_data = actor_stats[actor]\n",
    "    sorted_turker_data = sorted(turker_data.items(), key=operator.itemgetter(1))\n",
    "    predicted = np.array([actor_true_bp_predictions[actor][key[0]] for key in sorted_turker_data])\n",
    "    turker = np.array([turker_data[key[0]] for key in sorted_turker_data])\n",
    "    cor, pval = spearmanr(predicted, turker) \n",
    "    cors.append(cor)\n",
    "    pvals.append(pval)\n",
    "    print(spearmanr(predicted, turker))\n",
    "\n",
    "print('correlation')\n",
    "print(np.mean(np.array(cors)))    \n",
    "print('pvalue')\n",
    "print(np.mean(np.array(pvals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
