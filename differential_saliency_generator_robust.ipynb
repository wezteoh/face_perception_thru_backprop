{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# from alexnet_backprop import *\n",
    "from alexnet_guided_bp_vanilla_robust import *\n",
    "from utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import _pickle\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load test set images\n",
    "test_images = open('test_set_17_227.pkl', \"rb\")\n",
    "data_set = _pickle.load(test_images) \n",
    "actor_code = get_actor_code(data_set)[0]\n",
    "reversed_actor_code = get_actor_code(data_set)[1]\n",
    "\n",
    "# load weights\n",
    "weight_fpath = 'e2e17_result3/'\n",
    "weight_fname = 'end2end_weights.pkl'\n",
    "weight_fname = weight_fpath + weight_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_differential_saliency(data_set, actor, image_index, actor_code, graph, sess, foldername):\n",
    "    \n",
    "    image = data_set[actor][image_index].astype(np.float64)\n",
    "    image_feed = np.expand_dims(image,0)\n",
    "    \n",
    "    probabilities = sess.run(graph.probabilities, feed_dict={graph.inputs:image_feed})[0]\n",
    "    \n",
    "    plt.figure(dpi=70, figsize=(164, 9))\n",
    "    plt.subplots_adjust(bottom = 0.0, wspace=0.15, hspace = 0.1, top=2.5)\n",
    "    plt.subplot(1, 19, 1)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"True: \" + actor + \"\\n Pred: \" + actor_code[np.argmax(probabilities)], fontsize=14)\n",
    "    plt.imshow(image.astype('uint8'))\n",
    "\n",
    "    \n",
    "    one_hot_true = np.zeros(len(actor_code))\n",
    "    one_hot_true[reversed_actor_code[actor]] = 1\n",
    "    true_saliency = guided_backprop(graph, image, one_hot_true, sess)\n",
    "    \n",
    "    saliency_differences = []\n",
    "    for i in range(len(actor_code)):\n",
    "        one_hot = np.zeros(len(actor_code))\n",
    "        one_hot[i] = 1\n",
    "        plt.subplot(1, 19, i+2)\n",
    "        plt.axis('off')\n",
    "        plt.title(actor_code[i] + '\\n' + str(probabilities[i]), fontsize=14)\n",
    "        saliency = guided_backprop(graph, image, one_hot, sess)\n",
    "        saliency_diff = true_saliency - saliency\n",
    "        saliency_diff = (saliency_diff * (saliency_diff>0))\n",
    "        scaling_adjustment = 1E-20\n",
    "        threshold = np.percentile(saliency_diff,90)+scaling_adjustment\n",
    "#         saliency_diff = saliency_diff/(np.max(saliency_diff)+scaling_adjustment)\n",
    "        saliency_diff = saliency_diff/threshold\n",
    "        saliency_diff = saliency_diff* (saliency_diff <= 1) +  (saliency_diff >1)\n",
    "        \n",
    "        plt.imshow(saliency_diff)\n",
    "        saliency_differences.append(saliency_diff)\n",
    "    \n",
    "    mean_saliency_difference = np.sum(np.stack(saliency_differences), axis=0)\n",
    "    mean_saliency_difference = mean_saliency_difference/len(saliency_differences)\n",
    "    \n",
    "    plt.subplot(1, 19, 19)\n",
    "    plt.axis('off')\n",
    "    plt.title('Overall Saliency Difference')\n",
    "    \n",
    "#     saliency_rank = mean_saliency_difference.ravel().argsort().argsort().reshape(mean_saliency_difference.shape)\n",
    "#     saliency_mask = (saliency_rank > 227*227*0.85).astype(float)\n",
    "    \n",
    "#     plt.imshow(saliency_mask)\n",
    "    plt.imshow(mean_saliency_difference)\n",
    "    \n",
    "    fname = actor+ ' ' + str(image_index)+'.png'\n",
    "    path = os.path.join('robust_saliency_differences', foldername, 'raw')\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    plt.savefig(os.path.join(path, fname), bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return np.stack(saliency_differences)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1W (11, 11, 3, 96)\n",
      "1 conv1b (96,)\n",
      "2 conv2W (5, 5, 48, 256)\n",
      "3 conv2b (256,)\n",
      "4 conv3W (3, 3, 256, 384)\n",
      "5 conv3b (384,)\n",
      "6 conv4W (3, 3, 192, 384)\n",
      "7 conv4b (384,)\n",
      "8 conv5W (3, 3, 192, 256)\n",
      "9 conv5b (256,)\n",
      "10 fc1W (43264, 100)\n",
      "11 fc1b (100,)\n",
      "12 fc2W (100, 17)\n",
      "13 fc2b (17,)\n",
      "1688.9134504795074\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "b_graph = backprop_graph(17, 100, alexnet_face_classifier)\n",
    "b_graph.classifier_graph(temp=1.0)\n",
    "b_graph.guided_backprop_graph()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "diff_saliencies = {}\n",
    "with tf.Session() as sess:\n",
    "    b_graph.cnn.load_weights(weight_fname, sess)\n",
    "    for code in actor_code:\n",
    "        actor_diff_saliencies = []\n",
    "        for i in range(15):\n",
    "            actor_diff_saliencies.append(generate_differential_saliency(data_set, actor_code[code],\\\n",
    "                                                                        i, actor_code, b_graph, sess,\\\n",
    "                                                                       'saliency_diff_vanilla_temp1'))    \n",
    "        diff_saliencies[actor_code[code]] = np.stack(actor_diff_saliencies)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-970b25a188f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_saliencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'robust_diff_saliencies_vanilla_temp1.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_pickle.dump(diff_saliencies, open('robust_diff_saliencies_vanilla_temp1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 17, 227, 227)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_saliencies['Alec Baldwin'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_diff_saliencies = {}\n",
    "for actor in diff_saliencies:\n",
    "    temp = np.sum(diff_saliencies[actor], axis=1)\n",
    "    mean_diff_saliencies[actor] = temp/(len(diff_saliencies)-1)\n",
    "    \n",
    "_pickle.dump(mean_diff_saliencies, open('robust_mean_diff_saliencies_vanilla_temp1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for actor in diff_saliencies:\n",
    "    plt.figure(dpi=70, figsize=(164, 9))\n",
    "    plt.subplots_adjust(bottom = 0.0, wspace=0.15, hspace = 0.1, top=2.5)\n",
    "    mean_pairwise_diff = np.sum(diff_saliencies[actor], axis=0)\n",
    "    max_mean_pairwise_diff = mean_pairwise_diff\n",
    "    for _ in range(3):\n",
    "         max_mean_pairwise_diff = np.max(max_mean_pairwise_diff, axis=-1)\n",
    "    for _ in range(3):\n",
    "        max_mean_pairwise_diff = np.expand_dims(max_mean_pairwise_diff, axis=-1)\n",
    "    mean_pairwise_diff = mean_pairwise_diff/(max_mean_pairwise_diff+1E-20)\n",
    "    for i in range(len(mean_pairwise_diff)):\n",
    "        plt.subplot(1, 19, i+2)\n",
    "        plt.axis('off')\n",
    "        plt.title(actor + \" vs \" + actor_code[i], fontsize=14)\n",
    "        plt.imshow(mean_pairwise_diff[i])\n",
    "\n",
    "    mean_diff = np.sum(mean_diff_saliencies[actor], axis=0)\n",
    "    mean_diff = mean_diff/np.max(mean_diff)\n",
    "    plt.subplot(1, 19, 1)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"overall actor saliency\", fontsize=14)\n",
    "    plt.imshow(mean_diff)\n",
    "    \n",
    "    plt.subplot(1, 19, 19)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"overall actor saliency\", fontsize=14)\n",
    "    plt.imshow(mean_diff)\n",
    "    \n",
    "    fname = actor+ ' 15.png'\n",
    "    path = os.path.join('robust_saliency_differences', 'saliency_diff_vanilla_temp1', 'raw')\n",
    "    plt.savefig(os.path.join(path, fname), bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('robust_mean_diff_saliencies_vanilla_temp1.pkl', \"rb\") as handle:\n",
    "    mean_diff_saliencies = _pickle.load(handle) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_saliency_map(data_set, saliencies, saliency_coverage, graph, sess, fname):\n",
    "    \n",
    "    # save saliencies in an external array\n",
    "    saliency_masks = {}\n",
    "    plt.figure(dpi=70, figsize=(160, 130))\n",
    "    col=0\n",
    "    for actor in data_set:\n",
    "        row = 0 \n",
    "        saliency_masks[actor] = np.zeros((0,227,227))   \n",
    "        \n",
    "        for _ in range(len(data_set[actor])):\n",
    "            \n",
    "            # forward pass\n",
    "            image = data_set[actor][_].astype(np.float64)\n",
    "            image_feed = np.expand_dims(image,0)\n",
    "            probabilities = sess.run(graph.probabilities, feed_dict={graph.inputs:image_feed})[0]\n",
    "    \n",
    "            # plot original image\n",
    "            index = row*len(data_set)*2 + col +1\n",
    "            plt.subplots_adjust(bottom = 0.0, wspace=0.15, hspace = 0.1, top=1.0)\n",
    "            plt.subplot(len(data_set[actor]), len(data_set)*2, index)\n",
    "            plt.axis('off')\n",
    "            plt.title(\"True: \" + actor + \"\\n Pred: \" + actor_code[np.argmax(probabilities)], fontsize=14)\n",
    "            plt.imshow(image.astype('uint8'))\n",
    "    \n",
    "            # plot true class_saliency\n",
    "            i = reversed_actor_code[actor]\n",
    "            one_hot = np.zeros(len(actor_code))\n",
    "            one_hot[i] = 1\n",
    "            plt.subplot(len(data_set[actor]), len(data_set)*2, index+1)\n",
    "            plt.axis('off')\n",
    "            plt.title(actor + '\\n' + str(probabilities[i]), fontsize=14)\n",
    "            saliency = saliencies[actor][_]\n",
    "            saliency_rank = saliency.ravel().argsort().argsort().reshape(saliency.shape)\n",
    "            saliency_mask = (saliency_rank > 227*227*(1-saliency_coverage)).astype(float)\n",
    "            \n",
    "            plt.imshow(saliency_mask)\n",
    "\n",
    "            saliency_masks[actor] = np.vstack((saliency_masks[actor], np.expand_dims(saliency_mask, axis=0)))\n",
    "            \n",
    "            row += 1\n",
    "        col += 2\n",
    "    plt.savefig(fname +'.png')\n",
    "    plt.close()\n",
    "    \n",
    "    pickle_out = open(fname +\".pkl\",\"wb\")\n",
    "    _pickle.dump(saliency_masks, pickle_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1W (11, 11, 3, 96)\n",
      "1 conv1b (96,)\n",
      "2 conv2W (5, 5, 48, 256)\n",
      "3 conv2b (256,)\n",
      "4 conv3W (3, 3, 256, 384)\n",
      "5 conv3b (384,)\n",
      "6 conv4W (3, 3, 192, 384)\n",
      "7 conv4b (384,)\n",
      "8 conv5W (3, 3, 192, 256)\n",
      "9 conv5b (256,)\n",
      "10 fc1W (43264, 100)\n",
      "11 fc1b (100,)\n",
      "12 fc2W (100, 17)\n",
      "13 fc2b (17,)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    b_graph.cnn.load_weights(weight_fname, sess)\n",
    "    generate_saliency_map(data_set, mean_diff_saliencies, 0.2, b_graph, sess, \\\n",
    "                          'mean_diff_saliency_mask_vanilla_temp1_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
