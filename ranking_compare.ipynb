{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import _pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# todo\n",
    "# compare likelihoods\n",
    "# test with less popular features\n",
    "# use different priors\n",
    "# multiclass logistic regression significance tests\n",
    "# fit mixture of gaussian vs gaussian\n",
    "# check if weight activity killed\n",
    "# tansfer learning for new class and robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('true_class_saliency_mask_vanilla_temp1.pkl', \"rb\")\n",
    "# file = open('mean_diff_saliency_mask_vanilla_temp1.pkl', \"rb\")\n",
    "true_saliencies = _pickle.load(file) \n",
    "file = open('mean.pkl', \"rb\")\n",
    "gaussian_means = _pickle.load(file) \n",
    "file = open('covariance.pkl', \"rb\")\n",
    "gaussian_covariances = _pickle.load(file)\n",
    "\n",
    "with open('turker_prob.pkl', \"rb\") as handle:\n",
    "    turkers = _pickle.load(handle) \n",
    "\n",
    "with open('test_set_17_227.pkl', \"rb\") as handle:\n",
    "    test_set = _pickle.load(handle) \n",
    "    \n",
    "with open('turker_count.pkl', \"rb\") as handle:\n",
    "    turker_count= _pickle.load(handle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 227, 227)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_saliencies['Alec Baldwin'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_actors = ['Daniel Radcliffe', 'Gerard Butler', 'Michael Vartan', 'Alec Baldwin', 'Steve Carell',\\\n",
    "                    'Bill Hader', 'Fran Drescher', 'Matt Damon', 'Nicolas Cage']\n",
    "female_actors = ['Cheryl Hines', 'Selena Gomez', 'Angie Harmon', 'Lorraine Bracco', 'Kristin Chenoweth',\\\n",
    "                      'America Ferrera', 'Anne Hathaway', 'Jennifer Aniston']\n",
    "gender ={}\n",
    "for actor in male_actors:\n",
    "    gender[actor] = 'male'\n",
    "for actor in female_actors:\n",
    "    gender[actor] = 'female' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating turker coiunt per actor\n",
    "features = ['beard', 'eye brows', 'eyes', 'hairline', 'lips', 'moustache', 'nose']\n",
    "actor_stats = {}\n",
    "for actor in test_set:\n",
    "    actor_stats[actor] = {}\n",
    "    for feature in features:\n",
    "        actor_stats[actor][feature] = 0  \n",
    "    for stats in turker_count[actor]:\n",
    "        for feature in features:\n",
    "            try:\n",
    "                 actor_stats[actor][feature] += stats[feature]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "actor_stats_normalized = {}\n",
    "for actor in actor_stats:\n",
    "    actor_stats_normalized[actor] = {}\n",
    "    total_count = sum(actor_stats[actor].values())\n",
    "    for feature in features:\n",
    "        actor_stats_normalized[actor][feature] = actor_stats[actor][feature]/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual_prior(test_subject):\n",
    "\n",
    "    if gender[test_subject] == 'male':\n",
    "        actor_set = male_actors.copy()\n",
    "    else:\n",
    "        actor_set = female_actors.copy()\n",
    "    \n",
    "    actor_set.remove(test_subject)\n",
    "    prior = {}\n",
    "    for feature in features:\n",
    "        feature_stats = [actor_stats_normalized[actor][feature] for actor in actor_set]\n",
    "        feature_prior = sum(feature_stats)/len(feature_stats)\n",
    "        prior[feature] = feature_prior\n",
    "    \n",
    "    return prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# monte carlo rectangles generation\n",
    "def generate_rectangles(means, covariances):\n",
    "    mc_samples = {}\n",
    "    for feature in features:\n",
    "#         print(feature)\n",
    "        rectangles = []\n",
    "        while len(rectangles) < 100:\n",
    "#             print(len(rectangles))\n",
    "            width, height, y_centre, x_centre = np.random.multivariate_normal(means[feature], \\\n",
    "                                                                              covariances[feature])\n",
    "            x_0= int(np.round(x_centre - width/2)) \n",
    "            x_1= int(np.round(x_centre + width/2)) \n",
    "            y_0= int(np.round(226 - y_centre - height/2)) \n",
    "            y_1= int(np.round(226 - y_centre + height/2)) \n",
    "            \n",
    "#             x_0= int(np.round(x_centre - height/2)) \n",
    "#             x_1= int(np.round(x_centre + height/2)) \n",
    "#             y_0= int(np.round(y_centre - width/2)) \n",
    "#             y_1= int(np.round(y_centre + width/2)) \n",
    "            \n",
    "#             print(np.array([x_centre, y_centre, height, width]))\n",
    "#             print(np.array([x_0,x_1,y_0,y_1]))\n",
    "            if 0<= x_0 < x_1 <=226 and 0<= y_0 < y_1 <=226:\n",
    "                rectangles.append(np.array([x_0,x_1,y_0,y_1]))\n",
    "                \n",
    "        mc_samples[feature] = np.stack(rectangles)\n",
    "        \n",
    "    return mc_samples \n",
    "\n",
    "mc_rectangle_samples = generate_rectangles(gaussian_means, gaussian_covariances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def likelihood(rectangles, saliency_map):\n",
    "    scores = {}\n",
    "    for feature in features:\n",
    "        intensity_ratio_sum = 0\n",
    "        for rec in rectangles[feature]:\n",
    "            highlight = saliency_map[rec[2]:rec[3], rec[0]:rec[1]]\n",
    "            intensity_ratio = np.sum(highlight)/np.sum(saliency_map)\n",
    "            intensity_ratio_sum += intensity_ratio\n",
    "        scores[feature] = intensity_ratio_sum/len(rectangles[feature])\n",
    "    \n",
    "    sum_scores = np.sum(np.array(list(scores.values())))\n",
    "    probs = {}\n",
    "    \n",
    "    for feature in features:\n",
    "        probs[feature] = scores[feature]/sum_scores\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def posterior(rectangles, saliency_map, test_subject):\n",
    "    scores = {}\n",
    "    prior = create_individual_prior(test_subject)\n",
    "    for feature in features:\n",
    "        intensity_ratio_sum = 0\n",
    "        for rec in rectangles[feature]:\n",
    "            highlight = saliency_map[rec[2]:rec[3], rec[0]:rec[1]]\n",
    "            intensity_ratio = np.sum(highlight)/np.sum(saliency_map)\n",
    "            intensity_ratio_sum += intensity_ratio\n",
    "        scores[feature] = prior[feature]*intensity_ratio_sum/len(rectangles[feature])\n",
    "    \n",
    "    sum_scores = np.sum(np.array(list(scores.values())))\n",
    "    probs = {}\n",
    "    \n",
    "    for feature in sorted(scores.keys()):\n",
    "        probs[feature] = scores[feature]/sum_scores\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor_true_saliencies = {}\n",
    "\n",
    "for actor in true_saliencies:\n",
    "    actor_saliency = np.mean(true_saliencies[actor], axis=0)\n",
    "    actor_true_saliencies[actor] = actor_saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for actor in sorted(test_set.keys()):\n",
    "    saliency_map = actor_true_saliencies[actor]\n",
    "    probs = likelihood(mc_rectangle_samples, saliency_map)\n",
    "    predictions[actor]=probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_predictions = {}\n",
    "for actor in sorted(test_set.keys()):\n",
    "    saliency_map = actor_true_saliencies[actor]\n",
    "    probs = posterior(mc_rectangle_samples, saliency_map, actor)\n",
    "    posterior_predictions[actor]=probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main problems are with turker data\n",
    "# maybe imbalanced, also tend to label similar feature\n",
    "# maybe should try new set of actors who have very distinct features to do anchoring\n",
    "# people choocse what seems to get highlighted in that image, but not what is salient about the person\n",
    "# probaly better to frame questionas as what is salient about this individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec Baldwin\n",
      "America Ferrera\n",
      "Angie Harmon\n",
      "Anne Hathaway\n",
      "Bill Hader\n",
      "Cheryl Hines\n",
      "Daniel Radcliffe\n",
      "Fran Drescher\n",
      "Gerard Butler\n",
      "Jennifer Aniston\n",
      "Kristin Chenoweth\n",
      "Lorraine Bracco\n",
      "Matt Damon\n",
      "Michael Vartan\n",
      "Nicolas Cage\n",
      "Selena Gomez\n",
      "Steve Carell\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "actors = sorted(test_set.keys())\n",
    "\n",
    "f, axes = plt.subplots(17, 4, figsize=(60,170))\n",
    "\n",
    "for i in range(len(actors)):\n",
    "    actor = actors[i]\n",
    "    ax = axes[i]\n",
    "\n",
    "    ax[0].set_title(actor)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].imshow(actor_true_saliencies[actor])\n",
    "        \n",
    "    prediction = posterior_predictions[actor]\n",
    "    turker_data = actor_stats_normalized[actor]\n",
    "    sorted_turker_data = sorted(turker_data.items(), key=operator.itemgetter(1))\n",
    "    sorted_turker_data.reverse()\n",
    "    \n",
    "    X = np.arange(len(turker_data))\n",
    "    ax[1].set_ylim([0, 0.7])\n",
    "    ax[1].bar(X, [prediction[key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='b', align='center', label='Posterior Prediction')\n",
    "    ax[1].bar(X-0.2, [turker_data[key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='g', align='center', label='Turkers')\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xticks(X)\n",
    "    ax[1].set_xticklabels([key[0] for key in sorted_turker_data])\n",
    "    ax[1].set_title('turkers vs posterior', fontsize=17)\n",
    "    \n",
    "    \n",
    "    prediction = create_individual_prior(actor)\n",
    "    X = np.arange(len(turker_data))\n",
    "    ax[2].set_ylim([0, 0.7])\n",
    "    ax[2].bar(X, [prediction[key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='b', align='center', label='Prior Prediction')\n",
    "    ax[2].bar(X-0.2, [turker_data[key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='g', align='center', label='Turkers')\n",
    "    ax[2].legend()\n",
    "    ax[2].set_xticks(X)\n",
    "    ax[2].set_xticklabels([key[0] for key in sorted_turker_data])\n",
    "    ax[2].set_title('turkers vs prior', fontsize=17)\n",
    "    \n",
    "    prediction = predictions[actor]\n",
    "    X = np.arange(len(turker_data))\n",
    "    ax[3].set_ylim([0, 0.7])\n",
    "    ax[3].bar(X, [prediction[key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='b', align='center', label='Backprop Prediction')\n",
    "    ax[3].bar(X-0.2, [turker_data[key[0]] for key in sorted_turker_data],\\\n",
    "           width=0.2, color='g', align='center', label='Turkers')\n",
    "    ax[3].legend()\n",
    "    ax[3].set_xticks(X)\n",
    "    ax[3].set_xticklabels([key[0] for key in sorted_turker_data])\n",
    "    ax[3].set_title('turkers vs backprop', fontsize=17)\n",
    "\n",
    "    print(actor)\n",
    "    \n",
    "    \n",
    "plt.savefig('nomalized_prior_robust_predictions.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec Baldwin\n",
      "SpearmanrResult(correlation=0.99103120896511487, pvalue=1.4561252916129422e-05)\n",
      "America Ferrera\n",
      "SpearmanrResult(correlation=0.96362411165943163, pvalue=0.00047530433988404632)\n",
      "Angie Harmon\n",
      "SpearmanrResult(correlation=0.99103120896511487, pvalue=1.4561252916129422e-05)\n",
      "Anne Hathaway\n",
      "SpearmanrResult(correlation=0.95499371045729253, pvalue=0.00080553533630175773)\n",
      "Bill Hader\n",
      "SpearmanrResult(correlation=0.9189562119494703, pvalue=0.0034366261562175319)\n",
      "Cheryl Hines\n",
      "SpearmanrResult(correlation=0.84688121493382551, pvalue=0.016197127467871632)\n",
      "Daniel Radcliffe\n",
      "SpearmanrResult(correlation=0.96428571428571452, pvalue=0.00045414916919416892)\n",
      "Fran Drescher\n",
      "SpearmanrResult(correlation=0.92656164582637657, pvalue=0.0026974760978696771)\n",
      "Gerard Butler\n",
      "SpearmanrResult(correlation=0.67857142857142871, pvalue=0.093750253959831303)\n",
      "Jennifer Aniston\n",
      "SpearmanrResult(correlation=0.95499371045729253, pvalue=0.00080553533630175773)\n",
      "Kristin Chenoweth\n",
      "SpearmanrResult(correlation=0.95499371045729253, pvalue=0.00080553533630175773)\n",
      "Lorraine Bracco\n",
      "SpearmanrResult(correlation=0.96362411165943163, pvalue=0.00047530433988404632)\n",
      "Matt Damon\n",
      "SpearmanrResult(correlation=0.96428571428571452, pvalue=0.00045414916919416892)\n",
      "Michael Vartan\n",
      "SpearmanrResult(correlation=0.82142857142857151, pvalue=0.023448808345691505)\n",
      "Nicolas Cage\n",
      "SpearmanrResult(correlation=0.92857142857142883, pvalue=0.0025194724037946874)\n",
      "Selena Gomez\n",
      "SpearmanrResult(correlation=0.88291871344164785, pvalue=0.0084503423818966111)\n",
      "Steve Carell\n",
      "SpearmanrResult(correlation=0.84688121493382551, pvalue=0.016197127467871632)\n",
      "correlation\n",
      "0.914919625344\n",
      "pvalue\n",
      "0.0100589335185\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "cors = []\n",
    "pvals = []\n",
    "for actor in sorted(test_set.keys()):\n",
    "    print(actor)\n",
    "    turker_data = actor_stats[actor]\n",
    "    sorted_turker_data = sorted(turker_data.items(), key=operator.itemgetter(1))\n",
    "    prediction = posterior_predictions[actor]\n",
    "    predicted = np.array([prediction[key[0]] for key in sorted_turker_data])\n",
    "    turker = np.array([turker_data[key[0]] for key in sorted_turker_data])\n",
    "    cor, pval = spearmanr(predicted, turker) \n",
    "    cors.append(cor)\n",
    "    pvals.append(pval)\n",
    "    print(spearmanr(predicted, turker))\n",
    "print('correlation')\n",
    "print(np.mean(np.array(cors)))    \n",
    "print('pvalue')\n",
    "print(np.mean(np.array(pvals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec Baldwin\n",
      "SpearmanrResult(correlation=0.99103120896511487, pvalue=1.4561252916129422e-05)\n",
      "America Ferrera\n",
      "SpearmanrResult(correlation=0.96362411165943163, pvalue=0.00047530433988404632)\n",
      "Angie Harmon\n",
      "SpearmanrResult(correlation=0.99103120896511487, pvalue=1.4561252916129422e-05)\n",
      "Anne Hathaway\n",
      "SpearmanrResult(correlation=0.9189562119494703, pvalue=0.0034366261562175319)\n",
      "Bill Hader\n",
      "SpearmanrResult(correlation=0.9189562119494703, pvalue=0.0034366261562175319)\n",
      "Cheryl Hines\n",
      "SpearmanrResult(correlation=0.9189562119494703, pvalue=0.0034366261562175319)\n",
      "Daniel Radcliffe\n",
      "SpearmanrResult(correlation=0.8928571428571429, pvalue=0.0068071874089353918)\n",
      "Fran Drescher\n",
      "SpearmanrResult(correlation=0.88949917999332151, pvalue=0.0073394255616849513)\n",
      "Gerard Butler\n",
      "SpearmanrResult(correlation=0.75000000000000022, pvalue=0.052181400457057762)\n",
      "Jennifer Aniston\n",
      "SpearmanrResult(correlation=0.95499371045729253, pvalue=0.00080553533630175773)\n",
      "Kristin Chenoweth\n",
      "SpearmanrResult(correlation=0.99103120896511487, pvalue=1.4561252916129422e-05)\n",
      "Lorraine Bracco\n",
      "SpearmanrResult(correlation=0.96362411165943163, pvalue=0.00047530433988404632)\n",
      "Matt Damon\n",
      "SpearmanrResult(correlation=0.92857142857142883, pvalue=0.0025194724037946874)\n",
      "Michael Vartan\n",
      "SpearmanrResult(correlation=0.82142857142857151, pvalue=0.023448808345691505)\n",
      "Nicolas Cage\n",
      "SpearmanrResult(correlation=1.0, pvalue=0.0)\n",
      "Selena Gomez\n",
      "SpearmanrResult(correlation=0.88291871344164785, pvalue=0.0084503423818966111)\n",
      "Steve Carell\n",
      "SpearmanrResult(correlation=0.9189562119494703, pvalue=0.0034366261562175319)\n",
      "correlation\n",
      "0.923319732045\n",
      "pvalue\n",
      "0.00684076287993\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "cors = []\n",
    "pvals = []\n",
    "for actor in sorted(test_set.keys()):\n",
    "    print(actor)\n",
    "    turker_data = actor_stats[actor]\n",
    "    sorted_turker_data = sorted(turker_data.items(), key=operator.itemgetter(1))\n",
    "    prediction = create_individual_prior(actor)\n",
    "    predicted = np.array([prediction[key[0]] for key in sorted_turker_data])\n",
    "    turker = np.array([turker_data[key[0]] for key in sorted_turker_data])\n",
    "    cor, pval = spearmanr(predicted, turker) \n",
    "    cors.append(cor)\n",
    "    pvals.append(pval)\n",
    "    print(spearmanr(predicted, turker))\n",
    "print('correlation')\n",
    "print(np.mean(np.array(cors)))    \n",
    "print('pvalue')\n",
    "print(np.mean(np.array(pvals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec Baldwin\n",
      "SpearmanrResult(correlation=0.88291871344164785, pvalue=0.0084503423818966111)\n",
      "America Ferrera\n",
      "SpearmanrResult(correlation=0.92656164582637657, pvalue=0.0026974760978696771)\n",
      "Angie Harmon\n",
      "SpearmanrResult(correlation=0.79282496717209205, pvalue=0.033443543740541502)\n",
      "Anne Hathaway\n",
      "SpearmanrResult(correlation=0.79282496717209205, pvalue=0.033443543740541502)\n",
      "Bill Hader\n",
      "SpearmanrResult(correlation=0.88291871344164785, pvalue=0.0084503423818966111)\n",
      "Cheryl Hines\n",
      "SpearmanrResult(correlation=0.64285714285714302, pvalue=0.11939237342741094)\n",
      "Daniel Radcliffe\n",
      "SpearmanrResult(correlation=0.92857142857142883, pvalue=0.0025194724037946874)\n",
      "Fran Drescher\n",
      "SpearmanrResult(correlation=0.85243671416026634, pvalue=0.014814085490537589)\n",
      "Gerard Butler\n",
      "SpearmanrResult(correlation=0.53571428571428581, pvalue=0.21521745567801273)\n",
      "Jennifer Aniston\n",
      "SpearmanrResult(correlation=0.66669372239471369, pvalue=0.10192046024618222)\n",
      "Kristin Chenoweth\n",
      "SpearmanrResult(correlation=0.73876871941035849, pvalue=0.05785849689569271)\n",
      "Lorraine Bracco\n",
      "SpearmanrResult(correlation=0.55593698749582598, pvalue=0.19502242519495722)\n",
      "Matt Damon\n",
      "SpearmanrResult(correlation=1.0, pvalue=0.0)\n",
      "Michael Vartan\n",
      "SpearmanrResult(correlation=0.57142857142857151, pvalue=0.18020198891152739)\n",
      "Nicolas Cage\n",
      "SpearmanrResult(correlation=0.92857142857142883, pvalue=0.0025194724037946874)\n",
      "Selena Gomez\n",
      "SpearmanrResult(correlation=0.82886246567991428, pvalue=0.021173515581004269)\n",
      "Steve Carell\n",
      "SpearmanrResult(correlation=0.59461872537906901, pvalue=0.15908999370118462)\n",
      "correlation\n",
      "0.771912305807\n",
      "pvalue\n",
      "0.0680126463692\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "cors = []\n",
    "pvals = []\n",
    "for actor in sorted(test_set.keys()):\n",
    "    print(actor)\n",
    "    turker_data = actor_stats[actor]\n",
    "    sorted_turker_data = sorted(turker_data.items(), key=operator.itemgetter(1))\n",
    "    prediction = predictions[actor]\n",
    "    predicted = np.array([prediction[key[0]] for key in sorted_turker_data])\n",
    "    turker = np.array([turker_data[key[0]] for key in sorted_turker_data])\n",
    "    cor, pval = spearmanr(predicted, turker) \n",
    "    cors.append(cor)\n",
    "    pvals.append(pval)\n",
    "    print(spearmanr(predicted, turker))\n",
    "print('correlation')\n",
    "print(np.mean(np.array(cors)))    \n",
    "print('pvalue')\n",
    "print(np.mean(np.array(pvals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
